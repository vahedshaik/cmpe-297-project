{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vahedshaik/cmpe-297-project/blob/main/Classification_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f54c74-5b56-4179-aa37-0b78895fd8f1",
      "metadata": {
        "id": "c6f54c74-5b56-4179-aa37-0b78895fd8f1"
      },
      "source": [
        "# Training, Hyperparameter tuning and deploying a PyTorch BERT based Model on Vertex AI for Emotion Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8feed01-ef6e-45e9-9c61-f071fa39f31f",
      "metadata": {
        "id": "a8feed01-ef6e-45e9-9c61-f071fa39f31f"
      },
      "source": [
        "## Dataset:\n",
        "Emotion from Hugging Face Datasets:\n",
        "We have used this dataset for emotion classification by fine tuning the pretrained BERT model. The dataset contains labels belonging to multiple classes. It is a dataset of Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a226e49-3513-4540-85ec-1d73ea9b8d04",
      "metadata": {
        "id": "6a226e49-3513-4540-85ec-1d73ea9b8d04"
      },
      "source": [
        "## Set up the local environment for development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "415f1dfd-a5ba-4201-9a23-c5fe0dc32318",
      "metadata": {
        "id": "415f1dfd-a5ba-4201-9a23-c5fe0dc32318"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# The Google Cloud Notebook product has specific requirements\n",
        "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
        "\n",
        "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06dd933f-3611-465d-9f3f-db8699b7c7ec",
      "metadata": {
        "id": "06dd933f-3611-465d-9f3f-db8699b7c7ec"
      },
      "outputs": [],
      "source": [
        "!pip -q install {USER_FLAG} --upgrade transformers\n",
        "!pip -q install {USER_FLAG} --upgrade datasets\n",
        "!pip -q install {USER_FLAG} --upgrade tqdm\n",
        "!pip -q install {USER_FLAG} --upgrade cloudml-hypertune"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d111ba0b-7915-4526-b578-30ea494b7cf5",
      "metadata": {
        "id": "d111ba0b-7915-4526-b578-30ea494b7cf5"
      },
      "source": [
        "## Installing the Vertex SDK for Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbaa8fb1-bed2-4f97-81b1-11786e00c575",
      "metadata": {
        "id": "bbaa8fb1-bed2-4f97-81b1-11786e00c575"
      },
      "outputs": [],
      "source": [
        "!pip -q install {USER_FLAG} --upgrade google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "441634e5-b9e8-4d43-b24f-738a7bedcea9",
      "metadata": {
        "id": "441634e5-b9e8-4d43-b24f-738a7bedcea9"
      },
      "source": [
        "## **Need to restart the kernel here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dce92d6-0c71-4099-8ca7-88a58d0ca96b",
      "metadata": {
        "id": "5dce92d6-0c71-4099-8ca7-88a58d0ca96b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882ecebc-2ba0-4743-9664-88d68d4e36b3",
      "metadata": {
        "id": "882ecebc-2ba0-4743-9664-88d68d4e36b3"
      },
      "source": [
        "## Setting up the project details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ca2623-1a62-4f1c-ab1f-5d346d5baa8f",
      "metadata": {
        "id": "80ca2623-1a62-4f1c-ab1f-5d346d5baa8f",
        "outputId": "c8aa8089-1813-4317-acd8-768271b77ff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project ID:  starry-lens-333804\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"123456\"  # <---CHANGE THIS TO YOUR PROJECT\n",
        "\n",
        "import os\n",
        "\n",
        "# Get your Google Cloud project ID using google.auth\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    import google.auth\n",
        "\n",
        "    _, PROJECT_ID = google.auth.default()\n",
        "    print(\"Project ID: \", PROJECT_ID)\n",
        "\n",
        "# validate PROJECT_ID\n",
        "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"123456\":\n",
        "    print(\n",
        "        f\"Please set your project id before proceeding to next step. Currently it's set as {PROJECT_ID}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837721c7-b087-4224-b03a-11fd4e4d297a",
      "metadata": {
        "id": "837721c7-b087-4224-b03a-11fd4e4d297a",
        "outputId": "76609ee6-06f4-427d-f369-0d0eb5761a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TIMESTAMP = 20211209030542\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def get_timestamp():\n",
        "    return datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "\n",
        "TIMESTAMP = get_timestamp()\n",
        "print(f\"TIMESTAMP = {TIMESTAMP}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c7641a-8410-4958-bde0-275f07599adb",
      "metadata": {
        "id": "30c7641a-8410-4958-bde0-275f07599adb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "# The Google Cloud Notebook product has specific requirements\n",
        "IS_GOOG_CLD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
        "\n",
        "# If on Google Cloud Notebooks, then don't execute this code\n",
        "if not IS_GOOG_CLD_NOTEBOOK:\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d8f83f-ff45-44c4-a792-d19f9d53abaf",
      "metadata": {
        "id": "45d8f83f-ff45-44c4-a792-d19f9d53abaf"
      },
      "source": [
        "## Create a Cloud Storage bucket\n",
        "\n",
        "The cloud storage bucket helps in storing the model artifacts and hyperparameter tuning results. While creating and deploying the model on Vertex AI this is utilized. We created a cloud bucket by executing the following set of commands on the notebook instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b29e9b9f-69a9-415c-876f-704b3f749cf1",
      "metadata": {
        "id": "b29e9b9f-69a9-415c-876f-704b3f749cf1"
      },
      "outputs": [],
      "source": [
        "BCT_NAME = \"gs://[your-bucket-name]\"\n",
        "REGION = \"us-west1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2921c06-3a5c-4f46-8caf-e4388edeb576",
      "metadata": {
        "id": "e2921c06-3a5c-4f46-8caf-e4388edeb576"
      },
      "outputs": [],
      "source": [
        "if BCT_NAME == \"\" or BCT_NAME is None or BCT_NAME == \"gs://[your-bucket-name]\":\n",
        "    BCT_NAME = f\"gs://{PROJECT_ID}aip-{get_timestamp()}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80d19905-9f03-4187-a95f-d3ebd182e430",
      "metadata": {
        "id": "80d19905-9f03-4187-a95f-d3ebd182e430"
      },
      "outputs": [],
      "source": [
        "print(f\"PROJECT_ID = {PROJECT_ID}\")\n",
        "print(f\"BUCKET_NAME = {BCT_NAME}\")\n",
        "print(f\"REGION = {REGION}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2421b933-286e-40ae-b734-69343e547015",
      "metadata": {
        "id": "2421b933-286e-40ae-b734-69343e547015"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BCT_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae3deb9-c286-48da-b394-35e735ea5d17",
      "metadata": {
        "id": "3ae3deb9-c286-48da-b394-35e735ea5d17"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BCT_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecd5872a-2e77-460c-b1c8-c84b3a51d499",
      "metadata": {
        "id": "ecd5872a-2e77-460c-b1c8-c84b3a51d499"
      },
      "source": [
        "## Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a778bfc7-53bb-4e34-8b1b-8c8860d7fb95",
      "metadata": {
        "id": "a778bfc7-53bb-4e34-8b1b-8c8860d7fb95"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import google.auth\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import gapic as aip\n",
        "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
        "from google.protobuf.json_format import MessageToDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8395ccf0-db5a-4a39-ba52-75cbc8d74087",
      "metadata": {
        "id": "8395ccf0-db5a-4a39-ba52-75cbc8d74087"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e86cef2-9b8a-4bb1-af27-996b5087a8ad",
      "metadata": {
        "id": "5e86cef2-9b8a-4bb1-af27-996b5087a8ad"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from datasets import ClassLabel, Sequence, load_dataset\n",
        "from transformers import (AutoModelForSequenceClassification, AutoTokenizer,\n",
        "                          EvalPrediction, Trainer, TrainingArguments,\n",
        "                          default_data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e77171a-df77-4b2b-b7b3-c1051df267a7",
      "metadata": {
        "id": "2e77171a-df77-4b2b-b7b3-c1051df267a7",
        "outputId": "460be0f3-1363-4e38-b4a4-78f076c2d89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook runtime: GPU\n",
            "PyTorch version : 1.9.0\n",
            "Transformers version : 1.16.1\n",
            "Datasets version : 4.12.5\n"
          ]
        }
      ],
      "source": [
        "print(f\"Notebook runtime: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"PyTorch version : {torch.__version__}\")\n",
        "print(f\"Transformers version : {datasets.__version__}\")\n",
        "print(f\"Datasets version : {transformers.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c393b9a6-8058-4b48-9abf-42e3b4d407f6",
      "metadata": {
        "id": "c393b9a6-8058-4b48-9abf-42e3b4d407f6"
      },
      "outputs": [],
      "source": [
        "APP_NAME = \"finetuned-bert\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a7bbfb4-ddc0-4c96-bd1f-fed54e6ca822",
      "metadata": {
        "id": "7a7bbfb4-ddc0-4c96-bd1f-fed54e6ca822"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e3ffba5-b968-4d78-8b70-c37bc011ee1c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f96c530bbe254c2891c271f208804194",
            "27856d9648304ff097047bd2ceeac94a",
            "f08c990aec5848b7be413abfa05e2fda",
            "3952181f31514455a6e03ff851b762e9",
            "5c0ba1a623614798bb2ef6804abf6765",
            "",
            "cba60ed0d2684151b7b22b4b2ed0f08b"
          ]
        },
        "id": "7e3ffba5-b968-4d78-8b70-c37bc011ee1c",
        "outputId": "80208428-c793-40a5-c1c2-b4de3b25c47c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f96c530bbe254c2891c271f208804194",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27856d9648304ff097047bd2ceeac94a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default\n",
            "Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /home/jupyter/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f08c990aec5848b7be413abfa05e2fda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.66M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3952181f31514455a6e03ff851b762e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/204k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c0ba1a623614798bb2ef6804abf6765",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/207k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset emotion downloaded and prepared to /home/jupyter/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba60ed0d2684151b7b22b4b2ed0f08b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##Downloading and loading the emotion dataset from huggingface\n",
        "datasets = load_dataset(\"emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bd5b89-45a3-4882-9fbe-a553ae051d7c",
      "metadata": {
        "id": "51bd5b89-45a3-4882-9fbe-a553ae051d7c",
        "outputId": "1bd9360d-299b-48ed-a153-b7be4dfbaf3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 16000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Printing the dataset to see the structure\n",
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fadfe2da-7fee-49fd-bc65-d6edfce261ed",
      "metadata": {
        "id": "fadfe2da-7fee-49fd-bc65-d6edfce261ed",
        "outputId": "35f233c6-d4bd-466d-fa55-e0cc6ea059dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total # of rows in training dataset 16000 and size  4.05 MB\n",
            "Total # of rows in test dataset 2000 and size  4.05 MB\n"
          ]
        }
      ],
      "source": [
        "##Dataset shape\n",
        "print(\n",
        "    \"Total #  number of rows in training dataset {} and size {:5.2f} MB\".format(\n",
        "        datasets[\"train\"].shape[0], datasets[\"train\"].size_in_bytes / (1024 * 1024)\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Total # number of rows in test dataset {} and size {:5.2f} MB\".format(\n",
        "        datasets[\"test\"].shape[0], datasets[\"test\"].size_in_bytes / (1024 * 1024)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6347632-9e3b-4cb4-870f-2bb352aa719f",
      "metadata": {
        "id": "a6347632-9e3b-4cb4-870f-2bb352aa719f",
        "outputId": "84a07df3-7564-47b7-890a-5561ea54009b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'i didnt feel humiliated', 'label': 0}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "386932cb-a39c-4186-8c10-9194391a423e",
      "metadata": {
        "id": "386932cb-a39c-4186-8c10-9194391a423e",
        "outputId": "c7549ad3-ebe2-4913-a586-02323c6486b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 3, 2, 5, 4, 1]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Labels\n",
        "lbl= datasets[\"train\"].unique(\"label\")\n",
        "lbl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ef9dda-6a2d-4ce0-9e0f-bd39baddc53f",
      "metadata": {
        "id": "80ef9dda-6a2d-4ce0-9e0f-bd39baddc53f"
      },
      "outputs": [],
      "source": [
        "def show_random_elements(dataset, num_exms=2):\n",
        "    assert num_exms <= len(\n",
        "        dataset\n",
        "    ), \"Can't pick more elements than there are in the dataset.\"\n",
        "    pck = []\n",
        "    for _ in range(num_exms):\n",
        "        i = random.randint(0, len(dataset) - 1)\n",
        "        while i in pck:\n",
        "            i = random.randint(0, len(dataset) - 1)\n",
        "        pck.append(i)\n",
        "\n",
        "    dt = pd.DataFrame(dataset[pck])\n",
        "    for columns, tp in dataset.features.items():\n",
        "        if isinstance(tp, ClassLabel):\n",
        "            dt[columns] = dt[columns].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(tp.feature, ClassLabel):\n",
        "            dt[columns] = dt[columns].transform(\n",
        "                lambda x: [tp.feature.names[i] for i in x]\n",
        "            )\n",
        "    display(HTML(df.to_html()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ccb2b4-bb42-4cd2-a1db-e69cd65dc1f5",
      "metadata": {
        "id": "48ccb2b4-bb42-4cd2-a1db-e69cd65dc1f5",
        "outputId": "90ad59d7-66eb-4377-b2ce-6df80bc3f8e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i was feeling brave and wanted to try my hand at free motion quilting</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i could feel it but it didnt hurt</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_random_elements(datasets[\"train\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "027a950f-48ce-47ca-aa88-14d57af891da",
      "metadata": {
        "id": "027a950f-48ce-47ca-aa88-14d57af891da"
      },
      "source": [
        "## Data Preprocessing\n",
        "We used the ‘Tokenizer’ class from Hugging Face Transformers to tokenize and preprocess the input data to the format required by the model. The below screenshot represents a sample of the tokens created for input text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab97622-405c-4826-b64d-fb0290481bae",
      "metadata": {
        "id": "9ab97622-405c-4826-b64d-fb0290481bae"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "max_seq_length = 128\n",
        "model_name_or_path = \"bert-base-cased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9176e7-4b2e-43f8-9242-6529b8cebc70",
      "metadata": {
        "id": "3a9176e7-4b2e-43f8-9242-6529b8cebc70"
      },
      "outputs": [],
      "source": [
        "tknzr = AutoTokenizer.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    use_fast=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "326b4c4f-2144-4f20-b57d-55197d152a7d",
      "metadata": {
        "id": "326b4c4f-2144-4f20-b57d-55197d152a7d",
        "outputId": "5bebaed7-c717-4c79-ac9c-42fd19bddec4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 8667, 117, 1142, 1110, 1141, 5650, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tknzr(\"Hello, this is one sentence!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63516b50-1f37-49c8-ac2b-9a15fd86c05b",
      "metadata": {
        "id": "63516b50-1f37-49c8-ac2b-9a15fd86c05b",
        "outputId": "897c5545-2e33-4850-aafc-18ee01198d3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 8667, 1105, 1363, 2106, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Results of tokenizing\n",
        "tknzr(\"Hello and good morning!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eaef7b6-11fc-475a-bca0-b0533722c122",
      "metadata": {
        "id": "6eaef7b6-11fc-475a-bca0-b0533722c122",
        "outputId": "fd0d3814-f961-4b86-8d9f-28db9ff0bbf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': \"emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\", 'label': 1}\n"
          ]
        }
      ],
      "source": [
        "##Results of tokenizing\n",
        "acp = datasets[\"train\"][4]\n",
        "print(acp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e608f9a6-2f8f-4e99-a276-f592327ce8eb",
      "metadata": {
        "id": "e608f9a6-2f8f-4e99-a276-f592327ce8eb",
        "outputId": "80642f19-2b50-4fc5-84de-8af8e60ca07f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 8667, 117, 1142, 1110, 1141, 5650, 3325, 1154, 1734, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Results of tokenizing\n",
        "tknzr(\n",
        "    [\"Hello\", \",\", \"this\", \"is\", \"one\", \"sentence\", \"split\", \"into\", \"words\", \".\"],\n",
        "    is_split_into_words=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3edafa-6463-4f2a-85a2-292fb0c737cd",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7df37f4fb6bf4fea9db8196724764820",
            "c7c20f69a3074589b355fc4da72114a9",
            "3ce769e461644b18bc8dd7b99bde8530",
            "542e3b88e08a4aa3a84cb1d3816f7be6"
          ]
        },
        "id": "bc3edafa-6463-4f2a-85a2-292fb0c737cd",
        "outputId": "1ea93233-e236-44d8-ec4e-338a78aff074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default\n",
            "WARNING:datasets.builder:Reusing dataset emotion (/home/jupyter/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7df37f4fb6bf4fea9db8196724764820",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7c20f69a3074589b355fc4da72114a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ce769e461644b18bc8dd7b99bde8530",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "542e3b88e08a4aa3a84cb1d3816f7be6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Dataset loading repeated here to make this cell idempotent\n",
        "# Since we are over-writing datasets variable\n",
        "dts = load_dataset(\"emotion\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenize the input example texts\n",
        "    NOTE: The same preprocessing step(s) will be applied\n",
        "    at the time of inference as well.\n",
        "    \"\"\"\n",
        "    args = (examples[\"text\"],)\n",
        "    result = tokenizer(\n",
        "        *args, padding=\"max_length\", max_length=max_seq_length, truncation=True\n",
        "    )\n",
        "\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# apply preprocessing function to input examples\n",
        "dts = dts.map(preprocess_function, batched=True, load_from_cache_file=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "640d7a5b-8d9f-4852-b546-7fdb1e97c970",
      "metadata": {
        "id": "640d7a5b-8d9f-4852-b546-7fdb1e97c970"
      },
      "source": [
        "## Model fine-tuning\n",
        "Transfer learning is a technique where a deep learning model trained on a large dataset is used to perform similar tasks on another dataset. This is done by freezing the middle layers while modifying the input and output layers that are suitable for our task.\n",
        "\n",
        "In this study we are finetuning the BERT model which is pre-trained on a large corpus of unlabeled text including the entire Wikipedia (2,500 million words) and Book Corpus (800 million words). The advantage of using BERT includes only having to slightly tune it for the emotion classification task. This also results in quicker development and uses a much smaller dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2e44c0-57a4-4de4-820c-7ec4fdcf552f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c30f705a1f1341bcb39f6b58e4c1d293"
          ]
        },
        "id": "fe2e44c0-57a4-4de4-820c-7ec4fdcf552f",
        "outputId": "9b736593-251b-42ba-deb0-751f17ad2d49"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c30f705a1f1341bcb39f6b58e4c1d293",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "mdl = AutoModelForSequenceClassificationSequenceClassification.from_pretrained(\n",
        "    model_name_or_path, num_labels=len(label_list)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9875833d-7b4b-43f2-9300-c399ba532f05",
      "metadata": {
        "id": "9875833d-7b4b-43f2-9300-c399ba532f05"
      },
      "source": [
        "We create a trainer object with all the required parameters including learning rate, number of epochs, weight decay and batch size for training. The below screenshots show the same:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be06c5c-43cd-4474-bb33-78a806caaba6",
      "metadata": {
        "id": "2be06c5c-43cd-4474-bb33-78a806caaba6",
        "outputId": "dbb54244-ac80-497c-99e2-b1974ce1250f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "args = TrainingArguments(\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    output_dir=\"/tmp/cls\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bd1032d-cc20-4372-bce5-de1b3113ecc4",
      "metadata": {
        "id": "9bd1032d-cc20-4372-bce5-de1b3113ecc4"
      },
      "outputs": [],
      "source": [
        "def cpt_mtrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d180a695-2578-4b31-a95b-35c6631ccac6",
      "metadata": {
        "id": "d180a695-2578-4b31-a95b-35c6631ccac6"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=datasets[\"train\"],\n",
        "    eval_dataset=datasets[\"test\"],\n",
        "    data_collator=default_data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50ab6aa-7b35-4dc6-8139-110b4822ecd6",
      "metadata": {
        "id": "a50ab6aa-7b35-4dc6-8139-110b4822ecd6",
        "outputId": "6147471b-32da-475d-cc44-3603a5fd1dd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 16000\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 23:27, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.176300</td>\n",
              "      <td>0.273056</td>\n",
              "      <td>0.925000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.133700</td>\n",
              "      <td>0.206070</td>\n",
              "      <td>0.921000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.103600</td>\n",
              "      <td>0.247529</td>\n",
              "      <td>0.926000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.079000</td>\n",
              "      <td>0.321118</td>\n",
              "      <td>0.924000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.421277</td>\n",
              "      <td>0.924500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.039600</td>\n",
              "      <td>0.410756</td>\n",
              "      <td>0.926500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.451202</td>\n",
              "      <td>0.921500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.020100</td>\n",
              "      <td>0.447655</td>\n",
              "      <td>0.926000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.013600</td>\n",
              "      <td>0.476519</td>\n",
              "      <td>0.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.008700</td>\n",
              "      <td>0.485455</td>\n",
              "      <td>0.921000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /tmp/cls/checkpoint-500\n",
            "Configuration saved in /tmp/cls/checkpoint-500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-1000\n",
            "Configuration saved in /tmp/cls/checkpoint-1000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-1500\n",
            "Configuration saved in /tmp/cls/checkpoint-1500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-2000\n",
            "Configuration saved in /tmp/cls/checkpoint-2000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-2000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-2500\n",
            "Configuration saved in /tmp/cls/checkpoint-2500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-2500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-3000\n",
            "Configuration saved in /tmp/cls/checkpoint-3000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-3000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-3500\n",
            "Configuration saved in /tmp/cls/checkpoint-3500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-3500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-4000\n",
            "Configuration saved in /tmp/cls/checkpoint-4000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-4000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-4500\n",
            "Configuration saved in /tmp/cls/checkpoint-4500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-4500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-5000\n",
            "Configuration saved in /tmp/cls/checkpoint-5000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-5000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-5500\n",
            "Configuration saved in /tmp/cls/checkpoint-5500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-5500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-6000\n",
            "Configuration saved in /tmp/cls/checkpoint-6000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-6000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-6500\n",
            "Configuration saved in /tmp/cls/checkpoint-6500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-6500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-7000\n",
            "Configuration saved in /tmp/cls/checkpoint-7000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-7000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-7500\n",
            "Configuration saved in /tmp/cls/checkpoint-7500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-7500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-8000\n",
            "Configuration saved in /tmp/cls/checkpoint-8000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-8000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-8500\n",
            "Configuration saved in /tmp/cls/checkpoint-8500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-8500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-9000\n",
            "Configuration saved in /tmp/cls/checkpoint-9000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-9000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-9500\n",
            "Configuration saved in /tmp/cls/checkpoint-9500/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-9500/special_tokens_map.json\n",
            "Saving model checkpoint to /tmp/cls/checkpoint-10000\n",
            "Configuration saved in /tmp/cls/checkpoint-10000/config.json\n",
            "Model weights saved in /tmp/cls/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/cls/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/cls/checkpoint-10000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "history_train = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e1ee58-b037-441a-b215-f1cf31e1d0f2",
      "metadata": {
        "id": "d1e1ee58-b037-441a-b215-f1cf31e1d0f2",
        "outputId": "9d4f6808-fe3e-4960-ab32-6565fab1b9be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./models’: File exists\n"
          ]
        }
      ],
      "source": [
        "saved_model_path = \"./models\"\n",
        "!mkdir ./models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eaf6fd1-a43c-4f3b-b4d0-069763f6b9bf",
      "metadata": {
        "id": "2eaf6fd1-a43c-4f3b-b4d0-069763f6b9bf",
        "outputId": "9f506fc3-1765-4958-bbf4-e54e258f2e4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./models\n",
            "Configuration saved in ./models/config.json\n",
            "Model weights saved in ./models/pytorch_model.bin\n",
            "tokenizer config file saved in ./models/tokenizer_config.json\n",
            "Special tokens file saved in ./models/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69d2b7a7-e71c-4ce9-aa41-2aed04f76ffc",
      "metadata": {
        "id": "69d2b7a7-e71c-4ce9-aa41-2aed04f76ffc",
        "outputId": "26454c41-cddf-47f4-d360-6736f07897da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hstry = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e214efef-be4e-4bec-8698-8664d8867095",
      "metadata": {
        "id": "e214efef-be4e-4bec-8698-8664d8867095",
        "outputId": "edf4ec91-274c-41e8-b4ac-66b852d22908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
            "     |████████████████████████████████| 5.8 MB 7.8 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.19.5)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
            "     |████████████████████████████████| 781 kB 42.0 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.25.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.37.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (58.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.4.6)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "     |████████████████████████████████| 4.9 MB 79.5 MB/s            \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
            "     |████████████████████████████████| 288 kB 82.5 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.41.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.18.1)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "     |████████████████████████████████| 126 kB 78.2 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (4.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.10.0.2)\n",
            "Installing collected packages: werkzeug, tensorboard-plugin-wit, tensorboard-data-server, absl-py, tensorboard\n",
            "Successfully installed absl-py-1.0.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 werkzeug-2.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add04363-238b-407c-92b0-92fd7f88cf62",
      "metadata": {
        "id": "add04363-238b-407c-92b0-92fd7f88cf62"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "ts = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56f97f3a-d087-4d3b-8d08-48f9f9daf466",
      "metadata": {
        "id": "56f97f3a-d087-4d3b-8d08-48f9f9daf466",
        "outputId": "6e5539e0-648a-482a-e841-c33bd513be02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10000, training_loss=0.06252609403133393, metrics={'train_runtime': 1407.4847, 'train_samples_per_second': 113.678, 'train_steps_per_second': 7.105, 'total_flos': 1.052482019328e+16, 'train_loss': 0.06252609403133393, 'epoch': 10.0})"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1deb4032-40d0-450b-ae56-733ac5a84271",
      "metadata": {
        "id": "1deb4032-40d0-450b-ae56-733ac5a84271"
      },
      "source": [
        "## Running predictions locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9216eff-64fe-4fe2-aada-fcde11036556",
      "metadata": {
        "id": "f9216eff-64fe-4fe2-aada-fcde11036556"
      },
      "outputs": [],
      "source": [
        "ts.add_scalar(\"Evalutation Loss\", history['eval_loss'], history['epoch'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2b2c39-035e-4ea5-b5d6-b6d4e258f3e1",
      "metadata": {
        "id": "9b2b2c39-035e-4ea5-b5d6-b6d4e258f3e1"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"bert-base-cased\"\n",
        "label_text = {0: \"Sadness\", 1: \"Joy\", 2:\"love\", 3:\"anger\", 4:\"fear\"}\n",
        "saved_modelpath = saved_model_path\n",
        "\n",
        "\n",
        "def predict(input_text, saved_model_path):\n",
        "    # initialize tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "    # preprocess and encode input text\n",
        "    tokenizer_args = (input_text,)\n",
        "    predict_input = tokenizer(\n",
        "        *tokenizer_args,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    # load trained model\n",
        "    loaded_model = AutoModelForSequenceClassification.from_pretrained(saved_model_path)\n",
        "\n",
        "    # get predictions\n",
        "    output = loaded_model(predict_input[\"input_ids\"])\n",
        "\n",
        "    # return labels\n",
        "    label_id = torch.argmax(*output.to_tuple(), dim=1)\n",
        "\n",
        "    print(f\"Review text: {input_text}\")\n",
        "    print(f\"Sentiment : {label_text[label_id.item()]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52adfd2f-ce54-4293-b626-ec132921969f",
      "metadata": {
        "id": "52adfd2f-ce54-4293-b626-ec132921969f",
        "outputId": "e0f80003-4c8d-43c5-9b9b-1d5c6a1a29b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/jupyter/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/jupyter/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/jupyter/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading configuration file ./models/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file ./models/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./models.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review text: im feeling quite sad and sorry for myself but ill snap out of it soon\n",
            "Sentiment : Sadness\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# example #1\n",
        "rvw_text = (\n",
        "    \"im feeling quite sad and sorry for myself but ill snap out of it soon\"\n",
        ")\n",
        "predict_input = predict(rvw_text, saved_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "724a328f-4627-414b-ab09-f471abda0a77",
      "metadata": {
        "id": "724a328f-4627-414b-ab09-f471abda0a77"
      },
      "source": [
        "## Training on Vertex AI\n",
        "\n",
        "For larger datasets and models as in our case, building a training pipeline by leveraging Vertex AI is the most effective method. The training job on Vertex AI is carried out by packaging the code and creating a training pipeline to orchestrate a training job. The 3 steps we have followed are:\n",
        "\n",
        "• Packaging the training code as a Python source distribution\n",
        "\n",
        "• Hyperparameter training job\n",
        "\n",
        "• Finally running the training job"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6b1a1f-9a9a-4c09-bace-dfd7c012fe63",
      "metadata": {
        "id": "7e6b1a1f-9a9a-4c09-bace-dfd7c012fe63"
      },
      "source": [
        "### Running Custom Job on Vertex AI with a pre-built container\n",
        "\n",
        "We are using pre-built container for PyTorch and packaging the training application code by adding the following Python dependencies - transformers, datasets and tqdm - in the setup.py file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cebeb4bc-56b0-4429-8557-dfb358b1728d",
      "metadata": {
        "id": "cebeb4bc-56b0-4429-8557-dfb358b1728d"
      },
      "outputs": [],
      "source": [
        "TRN_IMAGE = (\n",
        "    \"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-7:latest\"\n",
        ")\n",
        "\n",
        "APP_DIR = \"python_package\"\n",
        "\n",
        "SRC_PCKG = f\"{PYTHON_PACKAGE_APPLICATION_DIR}/dist/trainer-0.1.tar.gz\"\n",
        "python_package_gcs_uri = (\n",
        "    f\"{BUCKET_NAME}/pytorch-on-gcp/{APP_NAME}/train/python_package/trainer-0.1.tar.gz\"\n",
        ")\n",
        "pyt_NAME = \"trainer.task\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdb8b629-4641-4db7-a48b-e8b4ac391237",
      "metadata": {
        "id": "cdb8b629-4641-4db7-a48b-e8b4ac391237",
        "outputId": "8cd67fed-eab7-469e-c7c8-799c76ed0d81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./python_package/setup.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./{PYTHON_PACKAGE_APPLICATION_DIR}/setup.py\n",
        "\n",
        "from setuptools import find_packages\n",
        "from setuptools import setup\n",
        "import setuptools\n",
        "\n",
        "from distutils.command.build import build as _build\n",
        "import subprocess\n",
        "\n",
        "\n",
        "REQUIRED_PACKAGES = [\n",
        "    'transformers',\n",
        "    'datasets',\n",
        "    'tqdm',\n",
        "    'cloudml-hypertune'\n",
        "]\n",
        "\n",
        "setup(\n",
        "    name='trainer',\n",
        "    version='0.1',\n",
        "    install_requires=REQUIRED_PACKAGES,\n",
        "    packages=find_packages(),\n",
        "    include_package_data=True,\n",
        "    description='Vertex AI | Training | PyTorch | Text Classification | Python Package'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816c0414-27ee-4cd5-9044-7a22a2171e3f",
      "metadata": {
        "id": "816c0414-27ee-4cd5-9044-7a22a2171e3f"
      },
      "source": [
        "### Running the custom training job locally to ensure no errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4cc1589-9b36-4330-89cb-b01fbefa723f",
      "metadata": {
        "id": "d4cc1589-9b36-4330-89cb-b01fbefa723f",
        "outputId": "75a7c9bd-e966-4d72-c81e-00af9475827e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running sdist\n",
            "running egg_info\n",
            "creating trainer.egg-info\n",
            "writing trainer.egg-info/PKG-INFO\n",
            "writing dependency_links to trainer.egg-info/dependency_links.txt\n",
            "writing requirements to trainer.egg-info/requires.txt\n",
            "writing top-level names to trainer.egg-info/top_level.txt\n",
            "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
            "reading manifest file 'trainer.egg-info/SOURCES.txt'\n",
            "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
            "running check\n",
            "warning: check: missing required meta-data: url\n",
            "\n",
            "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
            "\n",
            "creating trainer-0.1\n",
            "creating trainer-0.1/trainer\n",
            "creating trainer-0.1/trainer.egg-info\n",
            "copying files to trainer-0.1...\n",
            "copying README.md -> trainer-0.1\n",
            "copying setup.py -> trainer-0.1\n",
            "copying trainer/__init__.py -> trainer-0.1/trainer\n",
            "copying trainer/experiment.py -> trainer-0.1/trainer\n",
            "copying trainer/metadata.py -> trainer-0.1/trainer\n",
            "copying trainer/model.py -> trainer-0.1/trainer\n",
            "copying trainer/task.py -> trainer-0.1/trainer\n",
            "copying trainer/utils.py -> trainer-0.1/trainer\n",
            "copying trainer.egg-info/PKG-INFO -> trainer-0.1/trainer.egg-info\n",
            "copying trainer.egg-info/SOURCES.txt -> trainer-0.1/trainer.egg-info\n",
            "copying trainer.egg-info/dependency_links.txt -> trainer-0.1/trainer.egg-info\n",
            "copying trainer.egg-info/requires.txt -> trainer-0.1/trainer.egg-info\n",
            "copying trainer.egg-info/top_level.txt -> trainer-0.1/trainer.egg-info\n",
            "Writing trainer-0.1/setup.cfg\n",
            "creating dist\n",
            "Creating tar archive\n",
            "removing 'trainer-0.1' (and everything under it)\n"
          ]
        }
      ],
      "source": [
        "!cd {APP_DIR} && python3 setup.py sdist --formats=gztar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efdcc12d-31bb-4fbb-9ef0-2b07f76c99b2",
      "metadata": {
        "id": "efdcc12d-31bb-4fbb-9ef0-2b07f76c99b2",
        "outputId": "9f2a8553-4df7-4cd3-a735-922575fe2110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying file://python_package/dist/trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
            "/ [1 files][  5.8 KiB/  5.8 KiB]                                                \n",
            "Operation completed over 1 objects/5.8 KiB.                                      \n"
          ]
        }
      ],
      "source": [
        "!gsutil cp {source_package_file_name} {python_package_gcs_uri}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58663a33-62bf-48c4-b131-05b18c090636",
      "metadata": {
        "id": "58663a33-62bf-48c4-b131-05b18c090636",
        "outputId": "b033cfac-7e15-4902-950f-0b26d1934d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5971  2021-12-09T05:10:04Z  gs://starry-lens-333804aip-20211209030626/pytorch-on-gcp/finetuned-bert-classifier/train/python_package/trainer-0.1.tar.gz\n",
            "TOTAL: 1 objects, 5971 bytes (5.83 KiB)\n"
          ]
        }
      ],
      "source": [
        "!gsutil ls -l {python_package_gcs_uri}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcadf49f-e229-4c3b-ab18-26789d38f992",
      "metadata": {
        "id": "fcadf49f-e229-4c3b-ab18-26789d38f992",
        "outputId": "d63d914f-aab3-4ad7-ede1-446baeac5ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=16, hp_tune='n', job_dir=None, learning_rate=2e-05, model_name='finetuned-bert-classifier', num_epochs=1, seed=42, weight_decay=0.01)\n",
            "Using custom data configuration default\n",
            "Reusing dataset emotion (/home/jupyter/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n",
            "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 791.63it/s]\n",
            "100%|███████████████████████████████████████████| 16/16 [00:41<00:00,  2.60s/ba]\n",
            "100%|█████████████████████████████████████████████| 2/2 [00:05<00:00,  2.59s/ba]\n",
            "100%|█████████████████████████████████████████████| 2/2 [00:05<00:00,  2.76s/ba]\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 16000\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1000\n",
            "{'loss': 0.7083, 'learning_rate': 1e-05, 'epoch': 0.5}                          \n",
            " 50%|████████████████████                    | 500/1000 [01:04<01:03,  7.85it/s]Saving model checkpoint to /tmp/finetuned-bert-classifier/checkpoint-500\n",
            "Configuration saved in /tmp/finetuned-bert-classifier/checkpoint-500/config.json\n",
            "Model weights saved in /tmp/finetuned-bert-classifier/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/finetuned-bert-classifier/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/finetuned-bert-classifier/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.2476, 'learning_rate': 0.0, 'epoch': 1.0}                            \n",
            "100%|███████████████████████████████████████| 1000/1000 [02:11<00:00,  7.56it/s]Saving model checkpoint to /tmp/finetuned-bert-classifier/checkpoint-1000\n",
            "Configuration saved in /tmp/finetuned-bert-classifier/checkpoint-1000/config.json\n",
            "Model weights saved in /tmp/finetuned-bert-classifier/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/finetuned-bert-classifier/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/finetuned-bert-classifier/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "\n",
            "  0%|                                                   | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|█▍                                         | 4/125 [00:00<00:03, 34.30it/s]\u001b[A\n",
            "  6%|██▊                                        | 8/125 [00:00<00:04, 28.76it/s]\u001b[A\n",
            "  9%|███▋                                      | 11/125 [00:00<00:04, 27.54it/s]\u001b[A\n",
            " 11%|████▋                                     | 14/125 [00:00<00:04, 26.54it/s]\u001b[A\n",
            " 14%|█████▋                                    | 17/125 [00:00<00:04, 26.31it/s]\u001b[A\n",
            " 16%|██████▋                                   | 20/125 [00:00<00:04, 26.17it/s]\u001b[A\n",
            " 18%|███████▋                                  | 23/125 [00:00<00:03, 26.01it/s]\u001b[A\n",
            " 21%|████████▋                                 | 26/125 [00:00<00:03, 25.76it/s]\u001b[A\n",
            " 23%|█████████▋                                | 29/125 [00:01<00:03, 25.62it/s]\u001b[A\n",
            " 26%|██████████▊                               | 32/125 [00:01<00:03, 25.58it/s]\u001b[A\n",
            " 28%|███████████▊                              | 35/125 [00:01<00:03, 25.61it/s]\u001b[A\n",
            " 30%|████████████▊                             | 38/125 [00:01<00:03, 25.59it/s]\u001b[A\n",
            " 33%|█████████████▊                            | 41/125 [00:01<00:03, 25.60it/s]\u001b[A\n",
            " 35%|██████████████▊                           | 44/125 [00:01<00:03, 25.54it/s]\u001b[A\n",
            " 38%|███████████████▊                          | 47/125 [00:01<00:03, 25.57it/s]\u001b[A\n",
            " 40%|████████████████▊                         | 50/125 [00:01<00:02, 25.26it/s]\u001b[A\n",
            " 42%|█████████████████▊                        | 53/125 [00:02<00:02, 25.39it/s]\u001b[A\n",
            " 45%|██████████████████▊                       | 56/125 [00:02<00:02, 25.50it/s]\u001b[A\n",
            " 47%|███████████████████▊                      | 59/125 [00:02<00:02, 25.52it/s]\u001b[A\n",
            " 50%|████████████████████▊                     | 62/125 [00:02<00:02, 25.36it/s]\u001b[A\n",
            " 52%|█████████████████████▊                    | 65/125 [00:02<00:02, 25.27it/s]\u001b[A\n",
            " 54%|██████████████████████▊                   | 68/125 [00:02<00:02, 25.32it/s]\u001b[A\n",
            " 57%|███████████████████████▊                  | 71/125 [00:02<00:02, 25.48it/s]\u001b[A\n",
            " 59%|████████████████████████▊                 | 74/125 [00:02<00:02, 25.36it/s]\u001b[A\n",
            " 62%|█████████████████████████▊                | 77/125 [00:02<00:01, 25.39it/s]\u001b[A\n",
            " 64%|██████████████████████████▉               | 80/125 [00:03<00:01, 25.46it/s]\u001b[A\n",
            " 66%|███████████████████████████▉              | 83/125 [00:03<00:01, 25.58it/s]\u001b[A\n",
            " 69%|████████████████████████████▉             | 86/125 [00:03<00:01, 25.68it/s]\u001b[A\n",
            " 71%|█████████████████████████████▉            | 89/125 [00:03<00:01, 25.58it/s]\u001b[A\n",
            " 74%|██████████████████████████████▉           | 92/125 [00:03<00:01, 25.54it/s]\u001b[A\n",
            " 76%|███████████████████████████████▉          | 95/125 [00:03<00:01, 25.63it/s]\u001b[A\n",
            " 78%|████████████████████████████████▉         | 98/125 [00:03<00:01, 25.62it/s]\u001b[A\n",
            " 81%|█████████████████████████████████▏       | 101/125 [00:03<00:00, 25.59it/s]\u001b[A\n",
            " 83%|██████████████████████████████████       | 104/125 [00:04<00:00, 25.59it/s]\u001b[A\n",
            " 86%|███████████████████████████████████      | 107/125 [00:04<00:00, 25.67it/s]\u001b[A\n",
            " 88%|████████████████████████████████████     | 110/125 [00:04<00:00, 25.72it/s]\u001b[A\n",
            " 90%|█████████████████████████████████████    | 113/125 [00:04<00:00, 25.75it/s]\u001b[A\n",
            " 93%|██████████████████████████████████████   | 116/125 [00:04<00:00, 25.74it/s]\u001b[A\n",
            " 95%|███████████████████████████████████████  | 119/125 [00:04<00:00, 25.64it/s]\u001b[A\n",
            " 98%|████████████████████████████████████████ | 122/125 [00:04<00:00, 25.76it/s]\u001b[A\n",
            "                                                                                \u001b[A\n",
            "\u001b[A{'eval_loss': 0.19806665182113647, 'eval_accuracy': 0.9210000038146973, 'eval_runtime': 4.8928, 'eval_samples_per_second': 408.76, 'eval_steps_per_second': 25.548, 'epoch': 1.0}\n",
            "100%|███████████████████████████████████████| 1000/1000 [02:18<00:00,  7.56it/s]\n",
            "100%|█████████████████████████████████████████| 125/125 [00:04<00:00, 25.78it/s]\u001b[A\n",
            "                                                                                \u001b[A\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 138.385, 'train_samples_per_second': 115.619, 'train_steps_per_second': 7.226, 'train_loss': 0.47795490264892576, 'epoch': 1.0}\n",
            "100%|███████████████████████████████████████| 1000/1000 [02:18<00:00,  7.23it/s]\n",
            "Saving model checkpoint to /tmp/finetuned-bert-classifier\n",
            "Configuration saved in /tmp/finetuned-bert-classifier/config.json\n",
            "Model weights saved in /tmp/finetuned-bert-classifier/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/finetuned-bert-classifier/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/finetuned-bert-classifier/special_tokens_map.json\n",
            "Saved model files at /tmp/finetuned-bert-classifier\n",
            "To save model files in GCS bucket, please specify job_dir starting with gs://\n"
          ]
        }
      ],
      "source": [
        "!cd {APP_DIR} && python -m trainer.task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37ec490-f82e-4b47-b0a0-010428e34dbc",
      "metadata": {
        "id": "b37ec490-f82e-4b47-b0a0-010428e34dbc"
      },
      "source": [
        "## Running custom training job on Vertex AI\n",
        "\n",
        "We are using Vertex SDK for Python to create and submit training job to the Vertex pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "380df8aa-adc8-48ba-97b3-bc576393c5b8",
      "metadata": {
        "id": "380df8aa-adc8-48ba-97b3-bc576393c5b8"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, staging_bucket=BCT_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96409bc-1ce7-4e05-a966-f8f6cd1ea2c2",
      "metadata": {
        "id": "d96409bc-1ce7-4e05-a966-f8f6cd1ea2c2",
        "outputId": "36cac3e2-8f6c-4792-ab08-0b2e99133b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APP_NAME=finetuned-bert-classifier\n",
            "PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI=us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-7:latest\n",
            "python_package_gcs_uri=gs://starry-lens-333804aip-20211209030626/pytorch-on-gcp/finetuned-bert-classifier/train/python_package/trainer-0.1.tar.gz\n",
            "python_module_name=trainer.task\n"
          ]
        }
      ],
      "source": [
        "print(f\"APP_NAME={APP_NAME}\")\n",
        "print(\n",
        "    f\"PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI={TRAIN_URI}\"\n",
        ")\n",
        "print(f\"python_package_gcs_uri={python_package_gcs_uri}\")\n",
        "print(f\"python_module_name={python_module_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89185245-44f4-437f-b36f-cfcb2d579df7",
      "metadata": {
        "id": "89185245-44f4-437f-b36f-cfcb2d579df7",
        "outputId": "c63ccf15-23e2-4847-fa73-96df86cfac91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JOB_NAME=finetuned-bert-classifier-pytorch-pkg-ar-20211209051507\n"
          ]
        }
      ],
      "source": [
        "JOB_NAME = f\"{APP_NAME}-pytorch-pkg-ar-{get_timestamp()}\"\n",
        "print(f\"JOB_NAME={JOB_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "561b4975-deed-410b-a279-9fdf2c5a7939",
      "metadata": {
        "id": "561b4975-deed-410b-a279-9fdf2c5a7939"
      },
      "outputs": [],
      "source": [
        "jb = aiplatform.CustomPythonPackageTrainingJob(\n",
        "    display_name=f\"{JOB_NAME}\",\n",
        "    python_package_gcs_uri=python_package_gcs_uri,\n",
        "    python_module_name=python_module_name,\n",
        "    container_uri=PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54680a1-c7a4-4c4d-a1ea-5934ab9b56e2",
      "metadata": {
        "id": "f54680a1-c7a4-4c4d-a1ea-5934ab9b56e2",
        "outputId": "162a357c-aca3-49fc-9063-a79d1a00a577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:google.cloud.aiplatform.training_jobs:Training Output directory:\n",
            "gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974 \n",
            "INFO:google.cloud.aiplatform.training_jobs:View Training:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8078420892037677056?project=425328907110\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 current state:\n",
            "PipelineState.PIPELINE_STATE_PENDING\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 current state:\n",
            "PipelineState.PIPELINE_STATE_PENDING\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 current state:\n",
            "PipelineState.PIPELINE_STATE_PENDING\n",
            "INFO:google.cloud.aiplatform.training_jobs:View backing custom job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2502753447120470016?project=425328907110\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob run completed. Resource name: projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056\n",
            "WARNING:google.cloud.aiplatform.training_jobs:Training did not produce a Managed Model returning None. Training Pipeline projects/425328907110/locations/us-central1/trainingPipelines/8078420892037677056 is not configured to upload a Model. Create the Training Pipeline with model_serving_container_image_uri and model_display_name passed in. Ensure that your training script saves to model to os.environ['AIP_MODEL_DIR'].\n"
          ]
        }
      ],
      "source": [
        "training_args = [\"--num-epochs\", \"2\", \"--model-name\", \"finetuned-bert-classifier\"]\n",
        "\n",
        "model = jb.run(\n",
        "    replica_count=1,\n",
        "    machine_type=\"n1-standard-8\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_V100\",\n",
        "    accelerator_count=1,\n",
        "    args=training_args,\n",
        "    sync=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07980454-2fba-4dbf-83ca-7f381dfd48da",
      "metadata": {
        "id": "07980454-2fba-4dbf-83ca-7f381dfd48da"
      },
      "source": [
        "## Validating the model artifacts written to GCS by the training code after the job is successful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9e3897-1a27-412d-ae32-9a664521bc4f",
      "metadata": {
        "id": "2a9e3897-1a27-412d-ae32-9a664521bc4f",
        "outputId": "ec954caa-1d9c-4a70-9c5b-5a8564dab771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model artifacts are available at gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974\n"
          ]
        }
      ],
      "source": [
        "\n",
        "job_response = MessageToDict(job._gca_resource._pb)\n",
        "gcs_model_artifacts_uri = job_response[\"trainingTaskInputs\"][\"baseOutputDirectory\"][\n",
        "    \"outputUriPrefix\"\n",
        "]\n",
        "print(f\"Model artifacts are available at {gcs_model_artifacts_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b639b8-e67d-4bec-952b-607789db78ce",
      "metadata": {
        "id": "98b639b8-e67d-4bec-952b-607789db78ce",
        "outputId": "af5745a0-179f-4c9d-bcd2-48cb8b1552a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/:\n",
            "\n",
            "gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/:\n",
            "\n",
            "gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/finetuned-bert-classifier/:\n",
            "       993  2021-12-09T05:33:58Z  gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/finetuned-bert-classifier/config.json\n",
            " 433348873  2021-12-09T05:33:58Z  gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/finetuned-bert-classifier/pytorch_model.bin\n",
            "       112  2021-12-09T05:33:58Z  gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/finetuned-bert-classifier/special_tokens_map.json\n",
            "    435816  2021-12-09T05:33:58Z  gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/finetuned-bert-classifier/tokenizer.json\n",
            "       320  2021-12-09T05:33:53Z  gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/finetuned-bert-classifier/tokenizer_config.json\n",
            "      2863  2021-12-09T05:33:58Z  gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/finetuned-bert-classifier/training_args.bin\n",
            "    213450  2021-12-09T05:33:58Z  gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-05:15:42.974/model/finetuned-bert-classifier/vocab.txt\n",
            "TOTAL: 7 objects, 434002427 bytes (413.9 MiB)\n"
          ]
        }
      ],
      "source": [
        "!gsutil ls -lr $gcs_model_artifacts_uri/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358651fb-a0e8-4b70-94a3-12a24d37a1d7",
      "metadata": {
        "id": "358651fb-a0e8-4b70-94a3-12a24d37a1d7",
        "outputId": "d8224377-5329-4384-9b1e-486cafe5dde2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.container.images.describe) argument IMAGE_NAME: Must be specified.\n",
            "Usage: gcloud container images describe IMAGE_NAME [optional flags]\n",
            "  optional flags may be  --help\n",
            "\n",
            "For detailed information on this command and its flags, run:\n",
            "  gcloud container images describe --help\n"
          ]
        }
      ],
      "source": [
        "!gcloud container images describe $CUSTOM_TRAIN_IMAGE_URI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee2de3f1-278b-4ef5-a8d0-b90b22c6484c",
      "metadata": {
        "id": "ee2de3f1-278b-4ef5-a8d0-b90b22c6484c"
      },
      "source": [
        "## Running a Custom Job on Vertex Training with docker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36e7ccc3-8802-4591-b0bb-82d1ebf2ad7a",
      "metadata": {
        "id": "36e7ccc3-8802-4591-b0bb-82d1ebf2ad7a",
        "outputId": "12059e04-f84a-4fee-eaa5-86ccf030539a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./custom_container/Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./custom_container/Dockerfile\n",
        "\n",
        "# Use pytorch GPU base image\n",
        "FROM gcr.io/cloud-aiplatform/training/pytorch-gpu.1-7\n",
        "\n",
        "# set working directory\n",
        "WORKDIR /app\n",
        "\n",
        "# Install required packages\n",
        "RUN pip install google-cloud-storage transformers datasets tqdm cloudml-hypertune\n",
        "\n",
        "# Copies the trainer code to the docker image.\n",
        "COPY ./trainer/__init__.py /app/trainer/__init__.py\n",
        "COPY ./trainer/experiment.py /app/trainer/experiment.py\n",
        "COPY ./trainer/utils.py /app/trainer/utils.py\n",
        "COPY ./trainer/metadata.py /app/trainer/metadata.py\n",
        "COPY ./trainer/model.py /app/trainer/model.py\n",
        "COPY ./trainer/task.py /app/trainer/task.py\n",
        "\n",
        "# Set up the entry point to invoke the trainer.\n",
        "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "146d53c0-702f-4e57-8c87-fe9d3e74bd6f",
      "metadata": {
        "id": "146d53c0-702f-4e57-8c87-fe9d3e74bd6f"
      },
      "outputs": [],
      "source": [
        "TRAIN_IMAGE = f\"gcr.io/{PROJECT_ID}/pytorch_gpu_train_{APP_NAME}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0cb040-aab5-4b0c-b334-76b4d9e70070",
      "metadata": {
        "id": "0e0cb040-aab5-4b0c-b334-76b4d9e70070",
        "outputId": "4b577728-fdd4-4c82-eb40-b7f0df9cdef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon  56.37kB\n",
            "Step 1/10 : FROM gcr.io/cloud-aiplatform/training/pytorch-gpu.1-7\n",
            "latest: Pulling from cloud-aiplatform/training/pytorch-gpu.1-7\n",
            "\n",
            "\u001b[1B57c49d0f: Pulling fs layer \n",
            "\u001b[1B40447d26: Pulling fs layer \n",
            "\u001b[1B2f862619: Pulling fs layer \n",
            "\u001b[1B278deddf: Pulling fs layer \n",
            "\u001b[1B80049843: Pulling fs layer \n",
            "\u001b[1B556b2329: Pulling fs layer \n",
            "\u001b[1Ba0c97a55: Pulling fs layer \n",
            "\u001b[1B78bd0b24: Pulling fs layer \n",
            "\u001b[1B6c31766d: Pulling fs layer \n",
            "\u001b[1B39245b99: Pulling fs layer \n",
            "\u001b[1B5479a093: Pulling fs layer \n",
            "\u001b[1B5ca4da05: Pulling fs layer \n",
            "\u001b[1Bfd6e9dc5: Pulling fs layer \n",
            "\u001b[1Bbbe64fe2: Pulling fs layer \n",
            "\u001b[1Ba27fb552: Pulling fs layer \n",
            "\u001b[1Becec6186: Pulling fs layer \n",
            "\u001b[1Bcb91ab9d: Pulling fs layer \n",
            "\u001b[1B59d82e20: Pulling fs layer \n",
            "\u001b[1Bccae33a4: Pulling fs layer \n",
            "\u001b[1B6879b67d: Pulling fs layer \n",
            "\u001b[1B0a6966fa: Pulling fs layer \n",
            "\u001b[1B44eef141: Pulling fs layer \n",
            "\u001b[1B9633c8ef: Pulling fs layer \n",
            "\u001b[1Bc3344851: Pulling fs layer \n",
            "\u001b[1B4bc8487a: Pulling fs layer \n",
            "\u001b[1B2a518419: Pulling fs layer \n",
            "\u001b[1Bd2a1ad5c: Pulling fs layer \n",
            "\u001b[1Be5d4f578: Pulling fs layer \n",
            "\u001b[1B4022ba47: Pulling fs layer \n",
            "\u001b[1B2c6aa85d: Pulling fs layer \n",
            "\u001b[1B74fb19cf: Pulling fs layer \n",
            "\u001b[1B8d3b09c0: Pulling fs layer \n",
            "\u001b[1B13d6f4ce: Pulling fs layer \n",
            "\u001b[1Bedd4de7b: Pulling fs layer \n",
            "\u001b[1B10c5c488: Pulling fs layer \n",
            "\u001b[1B4e5f5ea3: Pulling fs layer \n",
            "\u001b[1Be8e4f00b: Pulling fs layer \n",
            "\u001b[1B37f1aba5: Pulling fs layer \n",
            "\u001b[1B54e610e1: Pulling fs layer \n",
            "\u001b[1B2c9f3a43: Pulling fs layer \n",
            "\u001b[1B007ff1db: Pulling fs layer \n",
            "\u001b[1BDigest: sha256:c66c5cb475ac9986984fcc3c5b5fa28e18ec3ea6df0db5dd4d96db96aad752fe2K\u001b[37A\u001b[2K\u001b[42A\u001b[2K\u001b[36A\u001b[2K\u001b[42A\u001b[2K\u001b[36A\u001b[2K\u001b[42A\u001b[2K\u001b[38A\u001b[2K\u001b[42A\u001b[2K\u001b[35A\u001b[2K\u001b[42A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[42A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[42A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[39A\u001b[2K\u001b[34A\u001b[2K\u001b[39A\u001b[2K\u001b[34A\u001b[2K\u001b[39A\u001b[2K\u001b[34A\u001b[2K\u001b[39A\u001b[2K\u001b[34A\u001b[2K\u001b[39A\u001b[2K\u001b[34A\u001b[2K\u001b[39A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[38A\u001b[2K\u001b[38A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[38A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[37A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2KDownloading  968.6MB/1.058GB\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[36A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[32A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[36A\u001b[2K\u001b[31A\u001b[2K\u001b[36A\u001b[2K\u001b[31A\u001b[2K\u001b[36A\u001b[2K\u001b[31A\u001b[2K\u001b[36A\u001b[2K\u001b[31A\u001b[2K\u001b[36A\u001b[2K\u001b[31A\u001b[2K\u001b[36A\u001b[2K\u001b[31A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[29A\u001b[2K\u001b[36A\u001b[2K\u001b[27A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[25A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[24A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[28A\u001b[2K\u001b[36A\u001b[2K\u001b[28A\u001b[2K\u001b[36A\u001b[2K\u001b[28A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[28A\u001b[2K\u001b[36A\u001b[2K\u001b[28A\u001b[2K\u001b[22A\u001b[2K\u001b[28A\u001b[2K\u001b[36A\u001b[2K\u001b[28A\u001b[2K\u001b[20A\u001b[2K\u001b[28A\u001b[2K\u001b[19A\u001b[2K\u001b[28A\u001b[2K\u001b[36A\u001b[2K\u001b[28A\u001b[2K\u001b[36A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[28A\u001b[2K\u001b[17A\u001b[2K\u001b[28A\u001b[2K\u001b[16A\u001b[2K\u001b[28A\u001b[2K\u001b[17A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[14A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[28A\u001b[2K\u001b[17A\u001b[2K\u001b[13A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[12A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[10A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[9A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[8A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[5A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[3A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[2A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2KDownloading  922.8MB/3.158GB\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[36A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[35A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[34A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[30A\u001b[2K\u001b[29A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[28A\u001b[2K\u001b[27A\u001b[2K\u001b[27A\u001b[2K\u001b[26A\u001b[2K\u001b[25A\u001b[2K\u001b[24A\u001b[2K\u001b[23A\u001b[2K\u001b[22A\u001b[2K\u001b[21A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2KExtracting  1.911GB/3.158GB\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\n",
            "Status: Downloaded newer image for gcr.io/cloud-aiplatform/training/pytorch-gpu.1-7:latest\n",
            " ---> 1d793c644e7e\n",
            "Step 2/10 : WORKDIR /app\n",
            " ---> Running in 63d2d323c336\n",
            "Removing intermediate container 63d2d323c336\n",
            " ---> 36a2a0837374\n",
            "Step 3/10 : RUN pip install google-cloud-storage transformers datasets tqdm cloudml-hypertune\n",
            " ---> Running in 118b856fe1b3\n",
            "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.7/site-packages (1.30.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.59.0)\n",
            "Requirement already satisfied: cloudml-hypertune in /opt/conda/lib/python3.7/site-packages (0.1.0.dev6)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.9.0)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.7.4)\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.3)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (20.9)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
            "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.2.0)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.3.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (4.2.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (49.6.0.post20210108)\n",
            "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (0.2.7)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (1.26.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (3.15.6)\n",
            "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (2021.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (1.53.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage) (2.20)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.11.0->google-cloud-storage) (0.4.8)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.3.17)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (20.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.6.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tqdm, fsspec, filelock, dill, xxhash, tokenizers, sacremoses, multiprocess, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.59.0\n",
            "    Uninstalling tqdm-4.59.0:\n",
            "      Successfully uninstalled tqdm-4.59.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 0.8.7\n",
            "    Uninstalling fsspec-0.8.7:\n",
            "      Successfully uninstalled fsspec-0.8.7\n",
            "Successfully installed datasets-1.16.1 dill-0.3.4 filelock-3.4.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multiprocess-0.70.12.2 sacremoses-0.0.46 tokenizers-0.10.3 tqdm-4.62.3 transformers-4.12.5 xxhash-2.0.2\n",
            "Removing intermediate container 118b856fe1b3\n",
            " ---> fdd08924f4dc\n",
            "Step 4/10 : COPY ./trainer/__init__.py /app/trainer/__init__.py\n",
            " ---> 26c0e4e72741\n",
            "Step 5/10 : COPY ./trainer/experiment.py /app/trainer/experiment.py\n",
            " ---> aa43a65916f5\n",
            "Step 6/10 : COPY ./trainer/utils.py /app/trainer/utils.py\n",
            " ---> 40eda4f1bfc5\n",
            "Step 7/10 : COPY ./trainer/metadata.py /app/trainer/metadata.py\n",
            " ---> e5a06d0d803b\n",
            "Step 8/10 : COPY ./trainer/model.py /app/trainer/model.py\n",
            " ---> 0a8ec7a112ba\n",
            "Step 9/10 : COPY ./trainer/task.py /app/trainer/task.py\n",
            " ---> e6298500abea\n",
            "Step 10/10 : ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
            " ---> Running in eee9b4f2eb2b\n",
            "Removing intermediate container eee9b4f2eb2b\n",
            " ---> 6a2e042f1559\n",
            "Successfully built 6a2e042f1559\n",
            "Successfully tagged gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier:latest\n"
          ]
        }
      ],
      "source": [
        "!cd ./custom_container/ && docker build -f Dockerfile -t $TRAIN_IMAGE ../python_package"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef06080-f8bd-4330-adde-e424216a7431",
      "metadata": {
        "id": "eef06080-f8bd-4330-adde-e424216a7431"
      },
      "source": [
        "## Pushing the container to Container Registry\n",
        "Belo code helps us in pushing our container image with training code and dependencies to the Container Registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e98f32d5-7adc-41f5-8eca-954e960f8b3e",
      "metadata": {
        "id": "e98f32d5-7adc-41f5-8eca-954e960f8b3e",
        "outputId": "8b4395ca-6820-49b1-e402-1e50857b0c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using default tag: latest\n",
            "The push refers to repository [gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier]\n",
            "\n",
            "\u001b[1Bafbb97e0: Preparing \n",
            "\u001b[1B108335c6: Preparing \n",
            "\u001b[1B3bbb2426: Preparing \n",
            "\u001b[1B9c05b48b: Preparing \n",
            "\u001b[1B9465adca: Preparing \n",
            "\u001b[1B08363895: Preparing \n",
            "\u001b[1Bd61e1dc6: Preparing \n",
            "\u001b[1B419e0a82: Preparing \n",
            "\u001b[1B6c56be71: Preparing \n",
            "\u001b[1B105d38de: Preparing \n",
            "\u001b[1Baacf220c: Preparing \n",
            "\u001b[1Beb8da3b6: Preparing \n",
            "\u001b[1B976e90b0: Preparing \n",
            "\u001b[1Bb42f0dc3: Preparing \n",
            "\u001b[1B86a69e4c: Preparing \n",
            "\u001b[1Bbf027b10: Preparing \n",
            "\u001b[1B53d15bde: Preparing \n",
            "\u001b[1B667fdca8: Preparing \n",
            "\u001b[1B20d6a257: Preparing \n",
            "\u001b[1B7f0ad120: Preparing \n",
            "\u001b[1B541dfbc1: Preparing \n",
            "\u001b[1Ba967deb1: Preparing \n",
            "\u001b[1Be620d847: Preparing \n",
            "\u001b[1Beceb9554: Preparing \n",
            "\u001b[1Bbb61b87c: Preparing \n",
            "\u001b[1B9c9eea04: Preparing \n",
            "\u001b[1B06241986: Preparing \n",
            "\u001b[1Ba36fa8ed: Preparing \n",
            "\u001b[1B9e6952e1: Preparing \n",
            "\u001b[1Baf6a03f9: Preparing \n",
            "\u001b[1B0507df07: Preparing \n",
            "\u001b[1B3f825d1f: Preparing \n",
            "\u001b[1B39619b27: Preparing \n",
            "\u001b[1B1ad956a3: Preparing \n",
            "\u001b[1B7c9f2e05: Preparing \n",
            "\u001b[1B37ca5432: Preparing \n",
            "\u001b[1Bbc973851: Preparing \n",
            "\u001b[1Bf53ba690: Preparing \n",
            "\u001b[1Bd71984bd: Preparing \n",
            "\u001b[1B014ab4a9: Preparing \n",
            "\u001b[1B10271917: Preparing \n",
            "\u001b[1B00c31be3: Preparing \n",
            "\u001b[1B18b890fc: Preparing \n",
            "\u001b[1Ba7c9e3d1: Preparing \n",
            "\u001b[1B4dce1444: Preparing \n",
            "\u001b[1B30bcc944: Preparing \n",
            "\u001b[1Be116c0c0: Preparing \n",
            "\u001b[1B4df0ad6c: Preparing \n",
            "\u001b[1Bdf553184: Preparing \n",
            "\u001b[4Be116c0c0: Mounted from cloud-aiplatform/training/pytorch-gpu.1-7 A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[41A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[40A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[45A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[35A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[36A\u001b[2K\u001b[33A\u001b[2K\u001b[32A\u001b[2K\u001b[31A\u001b[2K\u001b[44A\u001b[2K\u001b[29A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[23A\u001b[2K\u001b[25A\u001b[2K\u001b[21A\u001b[2K\u001b[20A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2Klatest: digest: sha256:3e360f75328589649ea52b55114057e2705cdecb377717eb1d311905501e9285 size: 10976\n"
          ]
        }
      ],
      "source": [
        "!docker push $TRAIN_IMAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e60f812c-b201-4e48-bb82-f55b512d8c0f",
      "metadata": {
        "id": "e60f812c-b201-4e48-bb82-f55b512d8c0f",
        "outputId": "fa3aca8a-e14a-4dd9-baa0-40388e5f12ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING:\u001b[0m Successfully resolved tag to sha256, but it is recommended to use sha256 directly.\n",
            "image_summary:\n",
            "  digest: sha256:3e360f75328589649ea52b55114057e2705cdecb377717eb1d311905501e9285\n",
            "  fully_qualified_digest: gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier@sha256:3e360f75328589649ea52b55114057e2705cdecb377717eb1d311905501e9285\n",
            "  registry: gcr.io\n",
            "  repository: starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier\n"
          ]
        }
      ],
      "source": [
        "##Validating the custom container image in Container Registry\n",
        "\n",
        "!gcloud container images describe $TRAIN_IMAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c51785c-dcc8-4835-be66-74e88e095b80",
      "metadata": {
        "id": "0c51785c-dcc8-4835-be66-74e88e095b80"
      },
      "source": [
        "## Initialize the Vertex SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2637398-c16d-45f6-9ce6-e53db263a902",
      "metadata": {
        "id": "e2637398-c16d-45f6-9ce6-e53db263a902"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, staging_bucket=BCT_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ec24f6-af83-4a03-bc13-5fc53356b643",
      "metadata": {
        "id": "30ec24f6-af83-4a03-bc13-5fc53356b643"
      },
      "source": [
        "## Configuring and submitting the Custom Job to Vertex Training pipeline\n",
        "We are Configuring a Custom Job with custom container image created with training code and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b28dd66-a1e8-47c2-a59d-83c00b2bb81d",
      "metadata": {
        "id": "2b28dd66-a1e8-47c2-a59d-83c00b2bb81d",
        "outputId": "1a24ea16-e267-4538-c048-9d320d0b72fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APP_NAME=finetuned-bert-classifier\n",
            "CUSTOM_TRAIN_IMAGE_URI=gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier\n",
            "JOB_NAME=finetuned-bert-classifier-pytorch-cstm-cntr-20211209060520\n"
          ]
        }
      ],
      "source": [
        "JOB_NAME = f\"{APP_NAME}-pytorch-cstm-cntr-{get_timestamp()}\"\n",
        "\n",
        "print(f\"APP_NAME={APP_NAME}\")\n",
        "print(f\"CUSTOM_TRAIN_IMAGE_URI={TRAIN_IMAGE}\")\n",
        "print(f\"JOB_NAME={JOB_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284f2c59-f829-43fc-a970-4ba130e6031b",
      "metadata": {
        "id": "284f2c59-f829-43fc-a970-4ba130e6031b"
      },
      "outputs": [],
      "source": [
        "# configure the job with container image spec\n",
        "jb = aiplatform.CustomContainerTrainingJob(\n",
        "    display_name=f\"{JOB_NAME}\", container_uri=f\"{TRAIN_IMAGE}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188630b9-96c5-47ae-88e0-967a2645bcc3",
      "metadata": {
        "id": "188630b9-96c5-47ae-88e0-967a2645bcc3"
      },
      "outputs": [],
      "source": [
        "# define training code arguments\n",
        "training_args = [\"--num-epochs\", \"2\", \"--model-name\", \"finetuned-bert-classifier\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac1c9c4-fa9c-4ac6-92c3-137f824873b1",
      "metadata": {
        "id": "7ac1c9c4-fa9c-4ac6-92c3-137f824873b1",
        "outputId": "1c897092-4853-4f35-bdb3-635d7ad194c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:google.cloud.aiplatform.training_jobs:Training Output directory:\n",
            "gs://starry-lens-333804aip-20211209030626/aiplatform-custom-training-2021-12-09-06:06:04.175 \n"
          ]
        }
      ],
      "source": [
        "# submit the custom job to Vertex training service\n",
        "mdl = job.run(\n",
        "    replica_count=1,\n",
        "    machine_type=\"n1-standard-8\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_V100\",\n",
        "    accelerator_count=1,\n",
        "    args=training_args,\n",
        "    sync=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1982f483-7ca5-4fb6-8d3e-a995101f2ff9",
      "metadata": {
        "id": "1982f483-7ca5-4fb6-8d3e-a995101f2ff9",
        "outputId": "63f608c4-6301-47b8-bcf6-6c12109c7020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING:\u001b[0m Successfully resolved tag to sha256, but it is recommended to use sha256 directly.\n",
            "image_summary:\n",
            "  digest: sha256:3e360f75328589649ea52b55114057e2705cdecb377717eb1d311905501e9285\n",
            "  fully_qualified_digest: gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier@sha256:3e360f75328589649ea52b55114057e2705cdecb377717eb1d311905501e9285\n",
            "  registry: gcr.io\n",
            "  repository: starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier\n"
          ]
        }
      ],
      "source": [
        "!gcloud container images describe $CUSTOM_TRAIN_IMAGE_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6271e28b-e704-4562-8f81-58d125daf828",
      "metadata": {
        "id": "6271e28b-e704-4562-8f81-58d125daf828"
      },
      "source": [
        "## Running Hyperparameter Tuning Job on Vertex AI\n",
        "We are experimenting with hyperparameters such as learning rate and weight decay while fine tuning the BERT model. These hyperparameter values are directly proportional to the behavior of the training algorithm and can have a significant impact on the performance of the model. We have automated the hyperparameter tuning with the Vertex Training service by packaging the training code and all dependencies in a Docker container. We then pushed the container to Google Container Registry.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f7247a-9150-405d-b3bd-7b9d20e484f2",
      "metadata": {
        "id": "99f7247a-9150-405d-b3bd-7b9d20e484f2"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0df1f57e-6423-4776-b0e7-8c4a5d1ac19d",
      "metadata": {
        "id": "0df1f57e-6423-4776-b0e7-8c4a5d1ac19d"
      },
      "source": [
        "### Configuring and submitting Hyperparameter Tuning Job to Vertex Training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282a7ef6-3e43-4f3d-a621-a4d0b1f141cd",
      "metadata": {
        "id": "282a7ef6-3e43-4f3d-a621-a4d0b1f141cd",
        "outputId": "e53a0ab7-b6b3-479d-a2d8-1c136735f522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APP_NAME=finetuned-bert-classifier\n",
            "CUSTOM_TRAIN_IMAGE_URI=gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier\n",
            "JOB_NAME=finetuned-bert-classifier-pytorch-hptune-20211209071625\n"
          ]
        }
      ],
      "source": [
        "JOB_NAME = f\"{APP_NAME}-pytorch-hptune-{get_timestamp()}\"\n",
        "\n",
        "print(f\"APP_NAME={APP_NAME}\")\n",
        "print(f\"CUSTOM_TRAIN_IMAGE_URI={CUSTOM_TRAIN_IMAGE_URI}\")\n",
        "print(f\"JOB_NAME={JOB_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74fd52c9-019a-468e-b0c9-7d77e50f587e",
      "metadata": {
        "id": "74fd52c9-019a-468e-b0c9-7d77e50f587e"
      },
      "outputs": [],
      "source": [
        "training_args = [\n",
        "    \"--num-epochs\",\n",
        "    \"2\",\n",
        "    \"--model-name\",\n",
        "    \"finetuned-bert-classifier\",\n",
        "    \"--hp-tune\",\n",
        "    \"y\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a38b021-b7d0-4e2e-b70a-61e1f01aee5f",
      "metadata": {
        "id": "2a38b021-b7d0-4e2e-b70a-61e1f01aee5f"
      },
      "outputs": [],
      "source": [
        "# The spec of the worker pools including machine type and Docker image\n",
        "pool_specialities = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": \"n1-standard-8\",\n",
        "            \"accelerator_type\": \"NVIDIA_TESLA_V100\",\n",
        "            \"accelerator_count\": 1,\n",
        "        },\n",
        "        \"replica_count\": 1,\n",
        "        \"container_spec\": {\"image_uri\": CUSTOM_TRAIN_IMAGE_URI, \"args\": training_args},\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33dfa2ea-2235-40a0-970a-cae57b38abb5",
      "metadata": {
        "id": "33dfa2ea-2235-40a0-970a-cae57b38abb5"
      },
      "outputs": [],
      "source": [
        "custom_job = aiplatform.CustomJob(\n",
        "    display_name=JOB_NAME, worker_pool_specialities=worker_pool_specs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522d11c5-13f8-4aea-ab0f-45d91327908e",
      "metadata": {
        "id": "522d11c5-13f8-4aea-ab0f-45d91327908e"
      },
      "outputs": [],
      "source": [
        "# Dictionary representing parameters to optimize.\n",
        "# The dictionary key is the parameter_id, which is passed into your training\n",
        "# job as a command line argument,\n",
        "# And the dictionary value is the parameter specification of the metric.\n",
        "prmtr_spec = {\n",
        "    \"learning-rate\": hpt.DoubleParameterSpec(min=1e-6, max=0.001, scale=\"log\"),\n",
        "    \"weight-decay\": hpt.DiscreteParameterSpec(\n",
        "        values=[0.0001, 0.001, 0.01, 0.1], scale=None\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8c37fb-b08f-4027-b7f9-75b2dc112820",
      "metadata": {
        "id": "ea8c37fb-b08f-4027-b7f9-75b2dc112820"
      },
      "outputs": [],
      "source": [
        "# Dictionary representing metrics to optimize.\n",
        "# The dictionary key is the metric_id, which is reported by your training job,\n",
        "# And the dictionary value is the optimization goal of the metric.\n",
        "metric_spec = {\"accuracy\": \"maximize\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8207429-aab4-4bb7-8368-d49fcc657bce",
      "metadata": {
        "id": "f8207429-aab4-4bb7-8368-d49fcc657bce"
      },
      "outputs": [],
      "source": [
        "JOB_NAME = \"finetuned-bert-classifier-pytorch-hptune-20211209072805\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "261a2d31-fa26-468d-89df-c84faaafc30b",
      "metadata": {
        "id": "261a2d31-fa26-468d-89df-c84faaafc30b"
      },
      "outputs": [],
      "source": [
        "hyper_job = aiplatform.HyperparameterTuningJob(\n",
        "    display_name=JOB_NAME,\n",
        "    custom_job=custom_job,\n",
        "    metric_spec=metric_spec,\n",
        "    parameter_spec=parameter_spec,\n",
        "    max_trial_count=5,\n",
        "    parallel_trial_count=2,\n",
        "    search_algorithm=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b943d3-9c6d-4ffa-a8ce-ebca5a9a6a10",
      "metadata": {
        "id": "c7b943d3-9c6d-4ffa-a8ce-ebca5a9a6a10",
        "outputId": "728fdf12-b09d-4d8f-cebe-9aaad2f0f1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:Creating HyperparameterTuningJob\n"
          ]
        }
      ],
      "source": [
        "mdl = hp_job.run(sync=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2d49ef-7ad5-4e33-8e1d-319ce91df0ae",
      "metadata": {
        "id": "bf2d49ef-7ad5-4e33-8e1d-319ce91df0ae"
      },
      "source": [
        "### Running docker container custom job locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192b8eda-9335-44ac-8fe4-222f50e4c407",
      "metadata": {
        "id": "192b8eda-9335-44ac-8fe4-222f50e4c407",
        "outputId": "60dfc09b-d1b6-4168-c135-81e0e7f1f216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=16, hp_tune='n', job_dir=None, learning_rate=2e-05, model_name='finetuned-bert-classifier', num_epochs=1, seed=42, weight_decay=0.01)\n",
            "Downloading: 3.62kB [00:00, 3.19MB/s]                                           \n",
            "Downloading: 3.28kB [00:00, 3.26MB/s]                                           \n",
            "Using custom data configuration default\n",
            "Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n",
            "Downloading: 100%|█████████████████████████| 1.66M/1.66M [00:00<00:00, 9.18MB/s]\n",
            "Downloading: 100%|███████████████████████████| 204k/204k [00:00<00:00, 2.52MB/s]\n",
            "Downloading: 100%|███████████████████████████| 207k/207k [00:00<00:00, 2.14MB/s]\n",
            "Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 561.69it/s]\n",
            "  0%|                                                    | 0/16 [00:00<?, ?ba/s]\n",
            "Downloading: 100%|███████████████████████████| 29.0/29.0 [00:00<00:00, 32.0kB/s]\u001b[A\n",
            "\n",
            "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 613kB/s]\u001b[A\n",
            "\n",
            "Downloading:   0%|                                   | 0.00/208k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:  13%|███▋                       | 28.0k/208k [00:00<00:00, 233kB/s]\u001b[A\n",
            "Downloading: 100%|████████████████████████████| 208k/208k [00:00<00:00, 855kB/s]\u001b[A\n",
            "\n",
            "Downloading:   0%|                                   | 0.00/426k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   7%|█▉                         | 30.0k/426k [00:00<00:01, 247kB/s]\u001b[A\n",
            "Downloading: 100%|███████████████████████████| 426k/426k [00:00<00:00, 1.39MB/s]\u001b[A\n",
            "100%|███████████████████████████████████████████| 16/16 [00:42<00:00,  2.67s/ba]\n",
            "100%|█████████████████████████████████████████████| 2/2 [00:05<00:00,  2.55s/ba]\n",
            "100%|█████████████████████████████████████████████| 2/2 [00:05<00:00,  2.57s/ba]\n",
            "Downloading: 100%|███████████████████████████| 416M/416M [00:19<00:00, 22.7MB/s]\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 16000\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1000\n",
            "{'loss': 0.8726, 'learning_rate': 1e-05, 'epoch': 0.5}                          \n",
            " 50%|████████████████████                    | 500/1000 [01:25<01:15,  6.58it/s]Saving model checkpoint to /tmp/finetuned-bert-classifier/checkpoint-500\n",
            "Configuration saved in /tmp/finetuned-bert-classifier/checkpoint-500/config.json\n",
            "Model weights saved in /tmp/finetuned-bert-classifier/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/finetuned-bert-classifier/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/finetuned-bert-classifier/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.2493, 'learning_rate': 0.0, 'epoch': 1.0}                            \n",
            "100%|███████████████████████████████████████| 1000/1000 [02:45<00:00,  6.59it/s]Saving model checkpoint to /tmp/finetuned-bert-classifier/checkpoint-1000\n",
            "Configuration saved in /tmp/finetuned-bert-classifier/checkpoint-1000/config.json\n",
            "Model weights saved in /tmp/finetuned-bert-classifier/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/finetuned-bert-classifier/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/finetuned-bert-classifier/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 16\n",
            "\n",
            "  0%|                                                   | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|█▍                                         | 4/125 [00:00<00:04, 28.87it/s]\u001b[A\n",
            "  6%|██▍                                        | 7/125 [00:00<00:04, 25.79it/s]\u001b[A\n",
            "  8%|███▎                                      | 10/125 [00:00<00:04, 24.98it/s]\u001b[A\n",
            " 10%|████▎                                     | 13/125 [00:00<00:04, 24.70it/s]\u001b[A\n",
            " 13%|█████▍                                    | 16/125 [00:00<00:04, 24.44it/s]\u001b[A\n",
            " 15%|██████▍                                   | 19/125 [00:00<00:04, 24.43it/s]\u001b[A\n",
            " 18%|███████▍                                  | 22/125 [00:00<00:04, 24.46it/s]\u001b[A\n",
            " 20%|████████▍                                 | 25/125 [00:01<00:04, 24.48it/s]\u001b[A\n",
            " 22%|█████████▍                                | 28/125 [00:01<00:03, 24.43it/s]\u001b[A\n",
            " 25%|██████████▍                               | 31/125 [00:01<00:03, 24.41it/s]\u001b[A\n",
            " 27%|███████████▍                              | 34/125 [00:01<00:03, 24.45it/s]\u001b[A\n",
            " 30%|████████████▍                             | 37/125 [00:01<00:03, 24.38it/s]\u001b[A\n",
            " 32%|█████████████▍                            | 40/125 [00:01<00:03, 24.25it/s]\u001b[A\n",
            " 34%|██████████████▍                           | 43/125 [00:01<00:03, 24.20it/s]\u001b[A\n",
            " 37%|███████████████▍                          | 46/125 [00:01<00:03, 24.25it/s]\u001b[A\n",
            " 39%|████████████████▍                         | 49/125 [00:01<00:03, 24.35it/s]\u001b[A\n",
            " 42%|█████████████████▍                        | 52/125 [00:02<00:03, 24.33it/s]\u001b[A\n",
            " 44%|██████████████████▍                       | 55/125 [00:02<00:02, 24.30it/s]\u001b[A\n",
            " 46%|███████████████████▍                      | 58/125 [00:02<00:02, 24.38it/s]\u001b[A\n",
            " 49%|████████████████████▍                     | 61/125 [00:02<00:02, 24.40it/s]\u001b[A\n",
            " 51%|█████████████████████▌                    | 64/125 [00:02<00:02, 21.10it/s]\u001b[A\n",
            " 54%|██████████████████████▌                   | 67/125 [00:02<00:02, 21.98it/s]\u001b[A\n",
            " 56%|███████████████████████▌                  | 70/125 [00:03<00:03, 18.01it/s]\u001b[A\n",
            " 58%|████████████████████████▌                 | 73/125 [00:03<00:02, 19.58it/s]\u001b[A\n",
            " 61%|█████████████████████████▌                | 76/125 [00:03<00:02, 20.84it/s]\u001b[A\n",
            " 63%|██████████████████████████▌               | 79/125 [00:03<00:02, 21.76it/s]\u001b[A\n",
            " 66%|███████████████████████████▌              | 82/125 [00:03<00:01, 22.55it/s]\u001b[A\n",
            " 68%|████████████████████████████▌             | 85/125 [00:03<00:01, 23.03it/s]\u001b[A\n",
            " 70%|█████████████████████████████▌            | 88/125 [00:03<00:01, 23.49it/s]\u001b[A\n",
            " 73%|██████████████████████████████▌           | 91/125 [00:03<00:01, 23.77it/s]\u001b[A\n",
            " 75%|███████████████████████████████▌          | 94/125 [00:04<00:01, 23.98it/s]\u001b[A\n",
            " 78%|████████████████████████████████▌         | 97/125 [00:04<00:01, 23.98it/s]\u001b[A\n",
            " 80%|████████████████████████████████▊        | 100/125 [00:04<00:01, 23.91it/s]\u001b[A\n",
            " 82%|█████████████████████████████████▊       | 103/125 [00:04<00:00, 23.93it/s]\u001b[A\n",
            " 85%|██████████████████████████████████▊      | 106/125 [00:04<00:00, 24.01it/s]\u001b[A\n",
            " 87%|███████████████████████████████████▊     | 109/125 [00:04<00:00, 24.20it/s]\u001b[A\n",
            " 90%|████████████████████████████████████▋    | 112/125 [00:04<00:00, 24.18it/s]\u001b[A\n",
            " 92%|█████████████████████████████████████▋   | 115/125 [00:04<00:00, 24.20it/s]\u001b[A\n",
            " 94%|██████████████████████████████████████▋  | 118/125 [00:05<00:00, 24.09it/s]\u001b[A\n",
            " 97%|███████████████████████████████████████▋ | 121/125 [00:05<00:00, 24.20it/s]\u001b[A\n",
            "                                                                                \u001b[A\n",
            "\u001b[A{'eval_loss': 0.19924457371234894, 'eval_accuracy': 0.9179999828338623, 'eval_runtime': 5.8039, 'eval_samples_per_second': 344.595, 'eval_steps_per_second': 21.537, 'epoch': 1.0}\n",
            "100%|███████████████████████████████████████| 1000/1000 [02:54<00:00,  6.59it/s]\n",
            "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.26it/s]\u001b[A\n",
            "                                                                                \u001b[A\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 174.1531, 'train_samples_per_second': 91.873, 'train_steps_per_second': 5.742, 'train_loss': 0.5609228744506836, 'epoch': 1.0}\n",
            "100%|███████████████████████████████████████| 1000/1000 [02:54<00:00,  5.74it/s]\n",
            "Saving model checkpoint to /tmp/finetuned-bert-classifier\n",
            "Configuration saved in /tmp/finetuned-bert-classifier/config.json\n",
            "Model weights saved in /tmp/finetuned-bert-classifier/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/finetuned-bert-classifier/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/finetuned-bert-classifier/special_tokens_map.json\n",
            "Saved model files at /tmp/finetuned-bert-classifier\n",
            "To save model files in GCS bucket, please specify job_dir starting with gs://\n"
          ]
        }
      ],
      "source": [
        "!docker run --gpus all -it --rm $CUSTOM_TRAIN_IMAGE_URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4793a0e9-216e-47d0-88e5-d294b05e28a7",
      "metadata": {
        "id": "4793a0e9-216e-47d0-88e5-d294b05e28a7",
        "outputId": "f9093e33-0166-43be-c408-2978164f02f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submitting PyTorch model training job to Vertex AI\n",
            "Sending build context to Docker daemon  56.48kB\n",
            "Step 1/10 : FROM gcr.io/cloud-aiplatform/training/pytorch-gpu.1-7\n",
            " ---> 1d793c644e7e\n",
            "Step 2/10 : WORKDIR /app\n",
            " ---> Running in 0b3086cd35f7\n",
            "Removing intermediate container 0b3086cd35f7\n",
            " ---> 92d0abbdc520\n",
            "Step 3/10 : RUN pip install google-cloud-storage transformers datasets tqdm cloudml-hypertune\n",
            " ---> Running in 8b693b1f1a40\n",
            "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.7/site-packages (1.30.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.59.0)\n",
            "Requirement already satisfied: cloudml-hypertune in /opt/conda/lib/python3.7/site-packages (0.1.0.dev6)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.9.0)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (20.9)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.3)\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.7.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
            "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.2.0)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.3.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (49.6.0.post20210108)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (4.7.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (0.2.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage) (4.2.1)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (1.26.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (1.53.0)\n",
            "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (2021.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage) (3.15.6)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage) (2.20)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.11.0->google-cloud-storage) (0.4.8)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.3.17)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (20.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tqdm, fsspec, filelock, dill, xxhash, tokenizers, sacremoses, multiprocess, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.59.0\n",
            "    Uninstalling tqdm-4.59.0:\n",
            "      Successfully uninstalled tqdm-4.59.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 0.8.7\n",
            "    Uninstalling fsspec-0.8.7:\n",
            "      Successfully uninstalled fsspec-0.8.7\n",
            "Successfully installed datasets-1.16.1 dill-0.3.4 filelock-3.4.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multiprocess-0.70.12.2 sacremoses-0.0.46 tokenizers-0.10.3 tqdm-4.62.3 transformers-4.12.5 xxhash-2.0.2\n",
            "Removing intermediate container 8b693b1f1a40\n",
            " ---> 437f1b78d705\n",
            "Step 4/10 : COPY ./trainer/__init__.py /app/trainer/__init__.py\n",
            " ---> e5b3914cc84c\n",
            "Step 5/10 : COPY ./trainer/experiment.py /app/trainer/experiment.py\n",
            " ---> 08dc7020db8c\n",
            "Step 6/10 : COPY ./trainer/utils.py /app/trainer/utils.py\n",
            " ---> a6ddba98f661\n",
            "Step 7/10 : COPY ./trainer/metadata.py /app/trainer/metadata.py\n",
            " ---> ccdaab2c66bc\n",
            "Step 8/10 : COPY ./trainer/model.py /app/trainer/model.py\n",
            " ---> beeaa68a9122\n",
            "Step 9/10 : COPY ./trainer/task.py /app/trainer/task.py\n",
            " ---> 377642004234\n",
            "Step 10/10 : ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
            " ---> Running in 163410fa9ee7\n",
            "Removing intermediate container 163410fa9ee7\n",
            " ---> e34e2f889d95\n",
            "Successfully built e34e2f889d95\n",
            "Successfully tagged gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier:latest\n",
            "The push refers to repository [gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier]\n",
            "\n",
            "\u001b[1Bc387da6b: Preparing \n",
            "\u001b[1B5a397542: Preparing \n",
            "\u001b[1B1ccc1a7f: Preparing \n",
            "\u001b[1B8715bce6: Preparing \n",
            "\u001b[1B32b40007: Preparing \n",
            "\u001b[1Bc2345e49: Preparing \n",
            "\u001b[1Bfb06edc1: Preparing \n",
            "\u001b[1Bdcec32e0: Preparing \n",
            "\u001b[1B6c56be71: Preparing \n",
            "\u001b[1B105d38de: Preparing \n",
            "\u001b[1Baacf220c: Preparing \n",
            "\u001b[1Beb8da3b6: Preparing \n",
            "\u001b[1B976e90b0: Preparing \n",
            "\u001b[1Bb42f0dc3: Preparing \n",
            "\u001b[1B86a69e4c: Preparing \n",
            "\u001b[1Bbf027b10: Preparing \n",
            "\u001b[1B53d15bde: Preparing \n",
            "\u001b[1B667fdca8: Preparing \n",
            "\u001b[1B20d6a257: Preparing \n",
            "\u001b[1B7f0ad120: Preparing \n",
            "\u001b[1B541dfbc1: Preparing \n",
            "\u001b[1Ba967deb1: Preparing \n",
            "\u001b[1Be620d847: Preparing \n",
            "\u001b[1Beceb9554: Preparing \n",
            "\u001b[1Bbb61b87c: Preparing \n",
            "\u001b[1B9c9eea04: Preparing \n",
            "\u001b[1B06241986: Preparing \n",
            "\u001b[1Ba36fa8ed: Preparing \n",
            "\u001b[1B9e6952e1: Preparing \n",
            "\u001b[1Baf6a03f9: Preparing \n",
            "\u001b[1B0507df07: Preparing \n",
            "\u001b[1B3f825d1f: Preparing \n",
            "\u001b[1B39619b27: Preparing \n",
            "\u001b[1B1ad956a3: Preparing \n",
            "\u001b[1B7c9f2e05: Preparing \n",
            "\u001b[1B37ca5432: Preparing \n",
            "\u001b[1Bbc973851: Preparing \n",
            "\u001b[1Bf53ba690: Preparing \n",
            "\u001b[1Bd71984bd: Preparing \n",
            "\u001b[1B014ab4a9: Preparing \n",
            "\u001b[1B10271917: Preparing \n",
            "\u001b[1B00c31be3: Preparing \n",
            "\u001b[1B18b890fc: Preparing \n",
            "\u001b[1Ba7c9e3d1: Preparing \n",
            "\u001b[1B4dce1444: Preparing \n",
            "\u001b[1B30bcc944: Preparing \n",
            "\u001b[1Be116c0c0: Preparing \n",
            "\u001b[1B4df0ad6c: Preparing \n",
            "\u001b[1Bdf553184: Preparing \n",
            "\u001b[44Bb06edc1: Pushed   53.87MB/52.11MB\u001b[46A\u001b[2K\u001b[48A\u001b[2K\u001b[50A\u001b[2K\u001b[44A\u001b[2K\u001b[42A\u001b[2K\u001b[44A\u001b[2K\u001b[41A\u001b[2K\u001b[44A\u001b[2K\u001b[39A\u001b[2K\u001b[37A\u001b[2K\u001b[44A\u001b[2K\u001b[34A\u001b[2K\u001b[33A\u001b[2K\u001b[31A\u001b[2K\u001b[30A\u001b[2K\u001b[29A\u001b[2K\u001b[44A\u001b[2K\u001b[27A\u001b[2K\u001b[25A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[21A\u001b[2K\u001b[19A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[44A\u001b[2K\u001b[43A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2K\u001b[44A\u001b[2Klatest: digest: sha256:f2b1511a8b6e45803d93d60d8b0b0417c44c8775df67a8bdd3e927b0548d1f62 size: 10976\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "CustomJob [projects/425328907110/locations/us-central1/customJobs/7960764351772622848] is submitted successfully.\n",
            "\n",
            "Your job is still active. You may view the status of your job with the command\n",
            "\n",
            "  $ gcloud beta ai custom-jobs describe projects/425328907110/locations/us-central1/customJobs/7960764351772622848\n",
            "\n",
            "or continue streaming the logs with the command\n",
            "\n",
            "  $ gcloud beta ai custom-jobs stream-logs projects/425328907110/locations/us-central1/customJobs/7960764351772622848\n",
            "After the job is completed successfully, model files will be saved at gs://cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77/finetuned-bert-classifier-pytorch-cstm-cntr-/models/finetuned-bert-classifier-pytorch-cstm-cntr--20211209064105-custom-job/\n"
          ]
        }
      ],
      "source": [
        "!cd custom_container && ./scripts/train-cloud.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a01c6a0-24d2-4999-8067-8638034ca3b8",
      "metadata": {
        "id": "6a01c6a0-24d2-4999-8067-8638034ca3b8"
      },
      "source": [
        "## Alternative way to submit hyperparameter job to Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce33911a-8d10-4c66-a2d4-4668a426b53c",
      "metadata": {
        "id": "ce33911a-8d10-4c66-a2d4-4668a426b53c",
        "outputId": "33e5245b-7abe-44f3-c2f3-17b192fc47fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching hyperparameter tuning job with display name as finetuned-bert-classifier-pytorch-hptune-20211209072805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-west1-aiplatform.googleapis.com/]\n",
            "Hyperparameter tuning job [919807447332290560] submitted successfully.\n",
            "\n",
            "Your job is still active. You may view the status of your job with the command\n",
            "\n",
            "  $ gcloud beta ai hp-tuning-jobs describe 919807447332290560 --region=us-west1\n",
            "\n",
            "Job State: JOB_STATE_PENDING\n"
          ]
        }
      ],
      "source": [
        "%%bash -s $BUCKET_NAME $APP_NAME\n",
        "\n",
        "# ========================================================\n",
        "# set job parameters\n",
        "# ========================================================\n",
        "# PROJECT_ID: Change to your project id\n",
        "PRJCT_ID=$(gcloud config list --format 'value(core.project)')\n",
        "\n",
        "# set job display name\n",
        "jb_pREFIX=\"finetuned-bert-classifier\"\n",
        "JB_NAME=${JOB_PREFIX}-pytorch-hptune-$(date +%Y%m%d%H%M%S)\n",
        "echo \"Launching hyperparameter tuning job with display name as \"$JOB_NAME\n",
        "\n",
        "# BUCKET_NAME: Change to your bucket name\n",
        "BCT_NAME=$1 # <-- CHANGE TO YOUR BUCKET NAME\n",
        "\n",
        "# APP_NAME: get application name\n",
        "APP_NAME=$2\n",
        "\n",
        "# JOB_DIR: Where to store prepared package and upload output model.\n",
        "JOB_DIR=${BUCKET_NAME}/${JOB_PREFIX}/model/${JOB_NAME}\n",
        "\n",
        "# custom container image URI\n",
        "TRAIN_IMAGE=\"gcr.io/starry-lens-333804/pytorch_gpu_train_finetuned-bert-classifier\"\n",
        "# CUSTOM_TRAIN_IMAGE_URI=f'gcr.io/'${PROJECT_ID}'/pytorch_gpu_train_'${APP_NAME}\n",
        "\n",
        "# ========================================================\n",
        "# create hyperparameter tuning configuration file\n",
        "# ========================================================\n",
        "cat << EOF > ./python_package/hptuning_job.yaml\n",
        "\n",
        "studySpec:\n",
        "  metrics:\n",
        "  - metricId: accuracy\n",
        "    goal: MAXIMIZE\n",
        "  parameters:\n",
        "  - parameterId: learning-rate\n",
        "    scaleType: UNIT_LOG_SCALE\n",
        "    doubleValueSpec:\n",
        "      minValue: 0.000001\n",
        "      maxValue: 0.001\n",
        "  - parameterId: weight-decay\n",
        "    scaleType: SCALE_TYPE_UNSPECIFIED\n",
        "    discreteValueSpec:\n",
        "      values: [\n",
        "          0.0001,\n",
        "          0.001,\n",
        "          0.01,\n",
        "          0.1\n",
        "      ]\n",
        "  measurementSelectionType: BEST_MEASUREMENT\n",
        "trialJobSpec:\n",
        "  workerPoolSpecs:\n",
        "  - machineSpec:\n",
        "      machineType: n1-standard-8\n",
        "      acceleratorType: NVIDIA_TESLA_V100\n",
        "      acceleratorCount: 1\n",
        "    replicaCount: 1\n",
        "    containerSpec:\n",
        "      imageUri: $CUSTOM_TRAIN_IMAGE_URI\n",
        "      args: [\"--num-epochs\", \"2\", \"--model-name\", \"finetuned-bert-classifier\", \"--hp-tune\", \"y\"]\n",
        "  baseOutputDirectory:\n",
        "    outputUriPrefix: $JOB_DIR/\n",
        "EOF\n",
        "\n",
        "# ========================================================\n",
        "# submit hyperparameter tuning job\n",
        "# ========================================================\n",
        "gcloud beta ai hp-tuning-jobs create \\\n",
        "   --config ./python_package/hptuning_job.yaml \\\n",
        "   --display-name $JOB_NAME \\\n",
        "   --algorithm algorithm-unspecified \\\n",
        "   --max-trial-count 5 \\\n",
        "   --parallel-trial-count 2 \\\n",
        "   --region=us-west1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7245fd2a-3cb1-4ab9-a48e-41e5e4adc8cb",
      "metadata": {
        "id": "7245fd2a-3cb1-4ab9-a48e-41e5e4adc8cb"
      },
      "source": [
        "### Getting the best model after hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b336ad7-d3cc-4d99-8472-0306374899af",
      "metadata": {
        "id": "3b336ad7-d3cc-4d99-8472-0306374899af"
      },
      "outputs": [],
      "source": [
        "def get_as_df(trials):\n",
        "    results = []\n",
        "    for trial in trials:\n",
        "        row = {}\n",
        "        t = MessageToDict(trial._pb)\n",
        "        # print(t)\n",
        "        row[\"Trial ID\"], row[\"Status\"], row[\"Start time\"], row[\"End time\"] = (\n",
        "            t[\"id\"],\n",
        "            t[\"state\"],\n",
        "            t[\"startTime\"],\n",
        "            t.get(\"endTime\", None),\n",
        "        )\n",
        "\n",
        "        for param in t[\"parameters\"]:\n",
        "            row[param[\"parameterId\"]] = param[\"value\"]\n",
        "\n",
        "        if t[\"state\"] == \"SUCCEEDED\":\n",
        "            row[\"Training step\"] = t[\"finalMeasurement\"][\"stepCount\"]\n",
        "            for metric in t[\"finalMeasurement\"][\"metrics\"]:\n",
        "                row[metric[\"metricId\"]] = metric[\"value\"]\n",
        "        results.append(row)\n",
        "\n",
        "    _df = pd.DataFrame(results)\n",
        "    return _df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32c86ef3-b70e-4fac-80cf-b170804f163d",
      "metadata": {
        "id": "32c86ef3-b70e-4fac-80cf-b170804f163d"
      },
      "outputs": [],
      "source": [
        "!gsutil ls -r $best_model_artifact_uri"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8907d2d5-8171-4495-b54e-288056f5c9e8",
      "metadata": {
        "id": "8907d2d5-8171-4495-b54e-288056f5c9e8"
      },
      "source": [
        "## Deployment\n",
        "### Defining a custom text handler to preprocess and postprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeefcf86-a001-492d-8baf-db478753008c",
      "metadata": {
        "id": "aeefcf86-a001-492d-8baf-db478753008c",
        "outputId": "60debd88-c861-4063-d72e-7ce84ed18391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting predictor/custom_text_handler.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from ts.torch_handler.base_handler import BaseHandler\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class TransformersClassifierHandler(BaseHandler):\n",
        "    \"\"\"\n",
        "    The handler takes an input string and returns the classification text\n",
        "    based on the serialized transformers checkpoint.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(TransformersClassifierHandler, self).__init__()\n",
        "        self.initialized = False\n",
        "\n",
        "    def initialize(self, ctx):\n",
        "        \"\"\" Loads the model.pt file and initialized the model object.\n",
        "        Instantiates Tokenizer for preprocessor to use\n",
        "        Loads labels to name mapping file for post-processing inference response\n",
        "        \"\"\"\n",
        "        self.manifest = ctx.manifest\n",
        "\n",
        "        properties = ctx.system_properties\n",
        "        model_dir = properties.get(\"model_dir\")\n",
        "        self.device = torch.device(\"cuda:\" + str(properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Read model serialize/pt file\n",
        "        serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
        "        model_pt_path = os.path.join(model_dir, serialized_file)\n",
        "        if not os.path.isfile(model_pt_path):\n",
        "            raise RuntimeError(\"Missing the model.pt or pytorch_model.bin file\")\n",
        "\n",
        "        # Load model\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        logger.debug('Transformer model from path {0} loaded successfully'.format(model_dir))\n",
        "\n",
        "        # Ensure to use the same tokenizer used during training\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "        # Read the mapping file, index to object name\n",
        "        mapping_file_path = os.path.join(model_dir, \"index_to_name.json\")\n",
        "\n",
        "        if os.path.isfile(mapping_file_path):\n",
        "            with open(mapping_file_path) as f:\n",
        "                self.mapping = json.load(f)\n",
        "        else:\n",
        "            logger.warning('Missing the index_to_name.json file. Inference output will not include class name.')\n",
        "\n",
        "        self.initialized = True\n",
        "\n",
        "    def preprocess(self, data):\n",
        "        \"\"\" Preprocessing input request by tokenizing\n",
        "            Extend with your own preprocessing steps as needed\n",
        "        \"\"\"\n",
        "        text = data[0].get(\"data\")\n",
        "        if text is None:\n",
        "            text = data[0].get(\"body\")\n",
        "        sentences = text.decode('utf-8')\n",
        "        logger.info(\"Received text: '%s'\", sentences)\n",
        "\n",
        "        # Tokenize the texts\n",
        "        tokenizer_args = ((sentences,))\n",
        "        inputs = self.tokenizer(*tokenizer_args,\n",
        "                                padding='max_length',\n",
        "                                max_length=128,\n",
        "                                truncation=True,\n",
        "                                return_tensors = \"pt\")\n",
        "        return inputs\n",
        "\n",
        "    def inference(self, inputs):\n",
        "        \"\"\" Predict the class of a text using a trained transformer model.\n",
        "        \"\"\"\n",
        "        prediction = self.model(inputs['input_ids'].to(self.device))[0].argmax().item()\n",
        "\n",
        "        if self.mapping:\n",
        "            prediction = self.mapping[str(prediction)]\n",
        "\n",
        "        logger.info(\"Model predicted: '%s'\", prediction)\n",
        "        return [prediction]\n",
        "\n",
        "    def postprocess(self, inference_output):\n",
        "        return inference_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8d267c-31d2-4659-9cc3-7c529c720665",
      "metadata": {
        "id": "ee8d267c-31d2-4659-9cc3-7c529c720665",
        "outputId": "0f7ad31e-eee6-458f-d79b-0aee61698611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./predictor/index_to_name.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "{\n",
        "    \"0\": \"Sadness\",\n",
        "    \"1\": \"Joy\",\n",
        "    \"2\": \"love\",\n",
        "    \"3\": \"anger\",\n",
        "    \"4\": \"fear\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "353700cb-8501-439b-9c6e-35c6e1ebd8ae",
      "metadata": {
        "id": "353700cb-8501-439b-9c6e-35c6e1ebd8ae"
      },
      "outputs": [],
      "source": [
        "GCS_MODEL_ARTIFACTS_URI = best_model_artifact_uri\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6941ae89-0c82-4ed3-860b-5fe2906b6fe7",
      "metadata": {
        "id": "6941ae89-0c82-4ed3-860b-5fe2906b6fe7",
        "outputId": "a90a787c-2fdd-43fd-db5b-5909aaf6b83a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/:\n",
            "\n",
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/:\n",
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/config.json\n",
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/pytorch_model.bin\n",
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/special_tokens_map.json\n",
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/tokenizer.json\n",
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/tokenizer_config.json\n",
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/training_args.bin\n",
            "gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/vocab.txt\n"
          ]
        }
      ],
      "source": [
        "!gsutil ls -r $GCS_MODEL_ARTIFACTS_URI/model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba21ef55-c8a9-4c78-9e4c-5814275ae605",
      "metadata": {
        "id": "ba21ef55-c8a9-4c78-9e4c-5814275ae605",
        "outputId": "1a02298c-c8e8-4b27-ed08-369d2e3716f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/tokenizer.json...\n",
            "Copying gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/config.json...\n",
            "Copying gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/pytorch_model.bin...\n",
            "Copying gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/special_tokens_map.json...\n",
            "==> NOTE: You are downloading one or more large file(s), which would            \n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "Copying gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/tokenizer_config.json...\n",
            "Copying gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/training_args.bin...\n",
            "Copying gs://starry-lens-333804aip-20211209030626/finetuned-bert-classifier/model/finetuned-bert-classifier-pytorch-hptune-20211209072805/5/model/finetuned-bert-classifier/vocab.txt...\n",
            "\\ [7/7 files][413.9 MiB/413.9 MiB] 100% Done                                    \n",
            "Operation completed over 7 objects/413.9 MiB.                                    \n"
          ]
        }
      ],
      "source": [
        "!gsutil -m cp -r $GCS_MODEL_ARTIFACTS_URI/model/ ./predictor/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52de4413-0b96-4990-bac5-0a3cbbbc50e5",
      "metadata": {
        "id": "52de4413-0b96-4990-bac5-0a3cbbbc50e5",
        "outputId": "35dec61c-b844-4eb4-fc7d-38474819209a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./predictor/model:\n",
            "total 4\n",
            "drwxr-xr-x 2 jupyter jupyter 4096 Dec  9 08:55 finetuned-bert-classifier\n",
            "\n",
            "./predictor/model/finetuned-bert-classifier:\n",
            "total 423852\n",
            "-rw-r--r-- 1 jupyter jupyter       993 Dec  9 08:55 config.json\n",
            "-rw-r--r-- 1 jupyter jupyter       112 Dec  9 08:55 special_tokens_map.json\n",
            "-rw-r--r-- 1 jupyter jupyter       320 Dec  9 08:55 tokenizer_config.json\n",
            "-rw-r--r-- 1 jupyter jupyter    213450 Dec  9 08:55 vocab.txt\n",
            "-rw-r--r-- 1 jupyter jupyter    435816 Dec  9 08:55 tokenizer.json\n",
            "-rw-r--r-- 1 jupyter jupyter      2863 Dec  9 08:55 training_args.bin\n",
            "-rw-r--r-- 1 jupyter jupyter 433348873 Dec  9 08:55 pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "!ls -ltrR ./predictor/model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e91470f-22fb-4019-b418-d537434626a4",
      "metadata": {
        "id": "4e91470f-22fb-4019-b418-d537434626a4"
      },
      "source": [
        "## Building a custom docker container with the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41705946-bc9a-4324-98d6-00ad01ca7e5b",
      "metadata": {
        "id": "41705946-bc9a-4324-98d6-00ad01ca7e5b",
        "outputId": "6b1ac26c-6d72-4e17-ce31-e273e2281a06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./predictor/Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%bash -s $APP_NAME\n",
        "\n",
        "APP_NAME=$1\n",
        "\n",
        "cat << EOF > ./predictor/Dockerfile\n",
        "\n",
        "FROM pytorch/torchserve:latest-cpu\n",
        "\n",
        "# install dependencies\n",
        "RUN pip3 install transformers\n",
        "\n",
        "# copy model artifacts, custom handler and other dependencies\n",
        "COPY ./custom_text_handler.py /home/model-server/\n",
        "COPY ./index_to_name.json /home/model-server/\n",
        "COPY ./model/$APP_NAME/ /home/model-server/\n",
        "\n",
        "# create torchserve configuration file\n",
        "USER root\n",
        "RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
        "RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
        "RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
        "USER model-server\n",
        "\n",
        "# expose health and prediction listener ports from the image\n",
        "EXPOSE 7080\n",
        "EXPOSE 7081\n",
        "\n",
        "# create model archive file packaging model artifacts and dependencies\n",
        "RUN torch-model-archiver -f \\\n",
        "  --model-name=$APP_NAME \\\n",
        "  --version=1.0 \\\n",
        "  --serialized-file=/home/model-server/pytorch_model.bin \\\n",
        "  --handler=/home/model-server/custom_text_handler.py \\\n",
        "  --extra-files \"/home/model-server/config.json,/home/model-server/tokenizer.json,/home/model-server/training_args.bin,/home/model-server/tokenizer_config.json,/home/model-server/special_tokens_map.json,/home/model-server/vocab.txt,/home/model-server/index_to_name.json\" \\\n",
        "  --export-path=/home/model-server/model-store\n",
        "\n",
        "# run Torchserve HTTP serve to respond to prediction requests\n",
        "CMD [\"torchserve\", \\\n",
        "     \"--start\", \\\n",
        "     \"--ts-config=/home/model-server/config.properties\", \\\n",
        "     \"--models\", \\\n",
        "     \"$APP_NAME=$APP_NAME.mar\", \\\n",
        "     \"--model-store\", \\\n",
        "     \"/home/model-server/model-store\"]\n",
        "EOF\n",
        "\n",
        "echo \"Writing ./predictor/Dockerfile\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6662e5cd-587c-4f5a-8536-ff326f81e1fc",
      "metadata": {
        "id": "6662e5cd-587c-4f5a-8536-ff326f81e1fc",
        "outputId": "e6211a2c-60ab-4f26-9059-d6c7236dff20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUSTOM_PREDICTOR_IMAGE_URI = gcr.io/starry-lens-333804/pytorch_predict_finetuned-bert-classifier\n"
          ]
        }
      ],
      "source": [
        "PREDICTOR_IMAGE = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n",
        "print(f\"CUSTOM_PREDICTOR_IMAGE_URI = {CUSTOM_PREDICTOR_IMAGE_URI}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a57b946-25b2-4a30-a716-71ab5f0fb140",
      "metadata": {
        "id": "3a57b946-25b2-4a30-a716-71ab5f0fb140",
        "outputId": "3dba7acc-b3e1-4824-cb76-02963a9f5446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending build context to Docker daemon    434MB\n",
            "Step 1/14 : FROM pytorch/torchserve:latest-cpu\n",
            "latest-cpu: Pulling from pytorch/torchserve\n",
            "\n",
            "\u001b[1Bd2c87b75: Pulling fs layer \n",
            "\u001b[1B10be24e1: Pulling fs layer \n",
            "\u001b[1B7173dcfe: Pulling fs layer \n",
            "\u001b[1Bd40b7ebd: Pulling fs layer \n",
            "\u001b[1B7c5679f0: Pulling fs layer \n",
            "\u001b[1B1d21c9ce: Pulling fs layer \n",
            "\u001b[1Bd91f5b58: Pulling fs layer \n",
            "\u001b[1B2cd6c42d: Pulling fs layer \n",
            "\u001b[1B03a87009: Pulling fs layer \n",
            "\u001b[1Bcf069356: Pulling fs layer \n",
            "\u001b[1Bb700ef54: Pull complete   32B/32BB4kBB[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2KDownloading  2.668MB/205.6MB\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:31e04f199b5a070f53a519fe436eed9aacc55172891601e7224fd9c3ad95b2c2\n",
            "Status: Downloaded newer image for pytorch/torchserve:latest-cpu\n",
            " ---> 659d9f4840d5\n",
            "Step 2/14 : RUN pip3 install transformers\n",
            " ---> Running in a9e3e86087bb\n",
            "Collecting transformers\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/f1/7d1c2507ae984a8b075df530ebb1939de5291a7dfb3208b658aa1c547fd4/transformers-4.12.5-py3-none-any.whl (3.1MB)\n",
            "Collecting importlib-metadata; python_version < \"3.8\" (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/1f/e2238896149df09953efcc53bdcc7d23597d6c53e428c30e572eda5ec6eb/importlib_metadata-4.8.2-py3-none-any.whl\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/85/79b9e5b4e8d3c0ac657f4e8617713cca8408f6cdc65d2ee6554217cedff1/PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603kB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/09/b6/acb9709f28143c9131a83ea843b1db48d2739a3e06f0ba0ae620d049596a/huggingface_hub-0.2.1-py3-none-any.whl (61kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/venv/lib/python3.6/site-packages (from transformers)\n",
            "Requirement already satisfied: requests in /home/venv/lib/python3.6/site-packages (from transformers)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/venv/lib/python3.6/site-packages (from transformers)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/93/57/277ac1dc8b7e49f48c6fb74929dd32d27ea5e3c504a766f4420d28a673ef/regex-2021.11.10-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (670kB)\n",
            "Collecting sacremoses (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/36/bf/15f8df78bce5eee8223553123173f010d426565980e457c559a71ecbecc3/sacremoses-0.0.46-py3-none-any.whl (895kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/3b/b59c7bcacc4cccafcd6e927a9e191268657e79a0a75530132cbf03b22c47/filelock-3.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: packaging>=20.0 in /home/venv/lib/python3.6/site-packages (from transformers)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/venv/lib/python3.6/site-packages (from transformers)\n",
            "Collecting tokenizers<0.11,>=0.10.1 (from transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/20/3605db440db4f96d5ffd66b231a043ae451ec7e5e4d1a2fb6f20608006c4/tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /home/venv/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers)\n",
            "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/df/d4a4974a3e3957fd1c1fa3082366d7fff6e428ddb55f074bf64876f8e8ad/zipp-3.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /home/venv/lib/python3.6/site-packages (from requests->transformers)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/venv/lib/python3.6/site-packages (from requests->transformers)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /home/venv/lib/python3.6/site-packages (from requests->transformers)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/venv/lib/python3.6/site-packages (from requests->transformers)\n",
            "Requirement already satisfied: six in /home/venv/lib/python3.6/site-packages (from sacremoses->transformers)\n",
            "Collecting click (from sacremoses->transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/48/58/c8aa6a8e62cc75f39fee1092c45d6b6ba684122697d7ce7d53f64f98a129/click-8.0.3-py3-none-any.whl (97kB)\n",
            "Collecting joblib (from sacremoses->transformers)\n",
            "  Downloading https://files.pythonhosted.org/packages/3e/d5/0163eb0cfa0b673aa4fe1cd3ea9d8a81ea0f32e50807b0c295871e4aab2e/joblib-1.1.0-py2.py3-none-any.whl (306kB)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/venv/lib/python3.6/site-packages (from packaging>=20.0->transformers)\n",
            "Installing collected packages: zipp, importlib-metadata, pyyaml, filelock, huggingface-hub, regex, click, joblib, sacremoses, tokenizers, transformers\n",
            "Successfully installed click-8.0.3 filelock-3.4.0 huggingface-hub-0.2.1 importlib-metadata-4.8.2 joblib-1.1.0 pyyaml-6.0 regex-2021.11.10 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5 zipp-3.6.0\n",
            "Removing intermediate container a9e3e86087bb\n",
            " ---> adc3973b0f91\n",
            "Step 3/14 : COPY ./custom_text_handler.py /home/model-server/\n",
            " ---> 7a3c72fb313a\n",
            "Step 4/14 : COPY ./index_to_name.json /home/model-server/\n",
            " ---> 97c4a98d5d9f\n",
            "Step 5/14 : COPY ./model/finetuned-bert-classifier/ /home/model-server/\n",
            " ---> c73b2ca0e0ee\n",
            "Step 6/14 : USER root\n",
            " ---> Running in 80e594621447\n",
            "Removing intermediate container 80e594621447\n",
            " ---> a961b568e10f\n",
            "Step 7/14 : RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
            " ---> Running in 02d1e072ec58\n",
            "Removing intermediate container 02d1e072ec58\n",
            " ---> 1cadc90d4a96\n",
            "Step 8/14 : RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
            " ---> Running in 7a2c8c5be13a\n",
            "Removing intermediate container 7a2c8c5be13a\n",
            " ---> 183e0630f86d\n",
            "Step 9/14 : RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
            " ---> Running in 7f941ae83174\n",
            "Removing intermediate container 7f941ae83174\n",
            " ---> 8dd4b069fd71\n",
            "Step 10/14 : USER model-server\n",
            " ---> Running in f7e688adeab8\n",
            "Removing intermediate container f7e688adeab8\n",
            " ---> 369cabfee4ed\n",
            "Step 11/14 : EXPOSE 7080\n",
            " ---> Running in 10cc12978ed7\n",
            "Removing intermediate container 10cc12978ed7\n",
            " ---> 898d88369b83\n",
            "Step 12/14 : EXPOSE 7081\n",
            " ---> Running in 9a4b2ac8cc11\n",
            "Removing intermediate container 9a4b2ac8cc11\n",
            " ---> aaf00439ba79\n",
            "Step 13/14 : RUN torch-model-archiver -f   --model-name=finetuned-bert-classifier   --version=1.0   --serialized-file=/home/model-server/pytorch_model.bin   --handler=/home/model-server/custom_text_handler.py   --extra-files \"/home/model-server/config.json,/home/model-server/tokenizer.json,/home/model-server/training_args.bin,/home/model-server/tokenizer_config.json,/home/model-server/special_tokens_map.json,/home/model-server/vocab.txt,/home/model-server/index_to_name.json\"   --export-path=/home/model-server/model-store\n",
            " ---> Running in efa767197995\n",
            "Removing intermediate container efa767197995\n",
            " ---> dc37efc39b2f\n",
            "Step 14/14 : CMD [\"torchserve\",      \"--start\",      \"--ts-config=/home/model-server/config.properties\",      \"--models\",      \"finetuned-bert-classifier=finetuned-bert-classifier.mar\",      \"--model-store\",      \"/home/model-server/model-store\"]\n",
            " ---> Running in bfc3223cddea\n",
            "Removing intermediate container bfc3223cddea\n",
            " ---> 8ea3f0c12ed7\n",
            "Successfully built 8ea3f0c12ed7\n",
            "Successfully tagged gcr.io/starry-lens-333804/pytorch_predict_finetuned-bert-classifier:latest\n"
          ]
        }
      ],
      "source": [
        "!docker build \\\n",
        "  --tag=$CUSTOM_PREDICTOR_IMAGE_URI \\\n",
        "  ./predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5858f59c-c95b-4caf-a376-5fdb4a0b8765",
      "metadata": {
        "id": "5858f59c-c95b-4caf-a376-5fdb4a0b8765"
      },
      "source": [
        "### Run the container locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6167212-2338-4240-bc04-6e0a8fbc20bd",
      "metadata": {
        "id": "a6167212-2338-4240-bc04-6e0a8fbc20bd",
        "outputId": "c489b8d6-ce6b-4a93-f8de-84d7115309fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error response from daemon: No such container: local_bert_classifier\n",
            "fca2689ea970147c8e327b67f09c7f579a915b6704335db0004eb163ab0f9986\n"
          ]
        }
      ],
      "source": [
        "!docker stop local_bert_classifier\n",
        "!docker run -t -d --rm -p 7080:7080 --name=local_bert_classifier $CUSTOM_PREDICTOR_IMAGE_URI\n",
        "!sleep 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd6801da-8987-4d84-a510-8cdb19f1ae8d",
      "metadata": {
        "id": "cd6801da-8987-4d84-a510-8cdb19f1ae8d",
        "outputId": "39bf73a0-34c2-4ab6-9896-d286b3e3f7dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTAINER ID   IMAGE                                                                 COMMAND                  CREATED          STATUS          PORTS                                                            NAMES\n",
            "fca2689ea970   gcr.io/starry-lens-333804/pytorch_predict_finetuned-bert-classifier   \"/usr/local/bin/dock…\"   24 seconds ago   Up 23 seconds   7070-7071/tcp, 7081/tcp, 8080-8082/tcp, 0.0.0.0:7080->7080/tcp   local_bert_classifier\n",
            "e55a61e001ed   gcr.io/inverting-proxy/agent                                          \"/bin/sh -c '/opt/bi…\"   6 hours ago      Up 6 hours                                                                       proxy-agent\n"
          ]
        }
      ],
      "source": [
        "!docker ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bf82108-fcaa-47b2-93e2-ca1da41a6391",
      "metadata": {
        "id": "0bf82108-fcaa-47b2-93e2-ca1da41a6391",
        "outputId": "d790b9da-d69e-45e0-9201-4ea8199b06d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"status\": \"Healthy\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!curl http://localhost:7080/ping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a583e6de-dcb0-4d9c-ac6c-e4d1ccb6c41d",
      "metadata": {
        "id": "a583e6de-dcb0-4d9c-ac6c-e4d1ccb6c41d",
        "outputId": "1d22f756-0ddd-4a71-c5ad-a959dbbf65f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"predictions\": [\"Joy\"]}"
          ]
        }
      ],
      "source": [
        "%%bash -s $APP_NAME\n",
        "\n",
        "APP_NAME=$1\n",
        "\n",
        "cat > ./predictor/instances.json <<END\n",
        "{\n",
        "   \"instances\": [\n",
        "     {\n",
        "       \"data\": {\n",
        "         \"b64\": \"$(echo 'I love pizza' | base64 --wrap=0)\"\n",
        "       }\n",
        "     }\n",
        "   ]\n",
        "}\n",
        "END\n",
        "\n",
        "curl -s -X POST \\\n",
        "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
        "  -d @./predictor/instances.json \\\n",
        "  http://localhost:7080/predictions/$APP_NAME/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0aa904-f698-431c-bfa4-457c283e66cf",
      "metadata": {
        "id": "fb0aa904-f698-431c-bfa4-457c283e66cf"
      },
      "source": [
        "## Deploying the serving container to Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bbd177a-6a4a-4633-b350-1259c388d67e",
      "metadata": {
        "id": "5bbd177a-6a4a-4633-b350-1259c388d67e",
        "outputId": "ced3b61e-b483-4510-cc16-de784170acc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using default tag: latest\n",
            "The push refers to repository [gcr.io/starry-lens-333804/pytorch_predict_finetuned-bert-classifier]\n",
            "\n",
            "\u001b[1B7322eb6d: Preparing \n",
            "\u001b[1Bf8cd4e5e: Preparing \n",
            "\u001b[1B004756de: Preparing \n",
            "\u001b[1B855761fa: Preparing \n",
            "\u001b[1Babed59b2: Preparing \n",
            "\u001b[1B782ec13d: Preparing \n",
            "\u001b[1B56320d30: Preparing \n",
            "\u001b[1B58eacbff: Preparing \n",
            "\u001b[1Bbf18a086: Preparing \n",
            "\u001b[1Bd2b4edc6: Preparing \n",
            "\u001b[1B4d0230ad: Preparing \n",
            "\u001b[1Bf03ffca8: Preparing \n",
            "\u001b[1Bf2874ea9: Preparing \n",
            "\u001b[1Ba1d7f3ba: Preparing \n",
            "\u001b[1Bd7c91a07: Preparing \n",
            "\u001b[1Bc3f5e5be: Preparing \n",
            "\u001b[1B512fd434: Preparing \n",
            "\u001b[1B31fc0e08: Preparing \n",
            "\u001b[6Ba1d7f3ba: Pushed   818.9MB/812.1MB\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[14A\u001b[2K\u001b[12A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[12A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[14A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[12A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[12A\u001b[2K\u001b[19A\u001b[2K\u001b[12A\u001b[2K\u001b[19A\u001b[2K\u001b[12A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[8A\u001b[2K\u001b[19A\u001b[2K\u001b[9A\u001b[2K\u001b[15A\u001b[2K\u001b[7A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[12A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[7A\u001b[2K\u001b[15A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[3A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[2A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2KPushing  182.1MB/516.4MB\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[15A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2Klatest: digest: sha256:221b726ac4b8943631532e974bd7323950de33fd2396de9ca4cd11c442192cd4 size: 4287\n"
          ]
        }
      ],
      "source": [
        "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f9f0e4-d3ee-4580-b48d-6670dba49c3f",
      "metadata": {
        "id": "22f9f0e4-d3ee-4580-b48d-6670dba49c3f"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b49626a7-7e6e-4ca2-9ea5-0a90f4452956",
      "metadata": {
        "id": "b49626a7-7e6e-4ca2-9ea5-0a90f4452956"
      },
      "source": [
        "### Creating a Model resource with custom serving container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c230d679-c8d9-4be4-b23f-a543f62a5ac2",
      "metadata": {
        "id": "c230d679-c8d9-4be4-b23f-a543f62a5ac2"
      },
      "outputs": [],
      "source": [
        "VERSION = 1\n",
        "model_display_name = f\"{APP_NAME}-v{VERSION}\"\n",
        "model_description = \"PyTorch based text classifier with custom container\"\n",
        "\n",
        "MODEL_NAME = APP_NAME\n",
        "health_route = \"/ping\"\n",
        "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
        "serving_container_ports = [7080]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aada5f79-89ab-4f43-aa94-9bbf95474366",
      "metadata": {
        "id": "aada5f79-89ab-4f43-aa94-9bbf95474366",
        "outputId": "9ce5e34d-6ad3-4a53-d385-21c19883175c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:google.cloud.aiplatform.models:Creating Model\n",
            "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/425328907110/locations/us-central1/models/7271840052622131200/operations/6133184780105154560\n",
            "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/425328907110/locations/us-central1/models/7271840052622131200\n",
            "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
            "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/425328907110/locations/us-central1/models/7271840052622131200')\n",
            "finetuned-bert-classifier-v1\n",
            "projects/425328907110/locations/us-central1/models/7271840052622131200\n"
          ]
        }
      ],
      "source": [
        "model = aiplatform.Model.upload(\n",
        "    display_name=model_display_name,\n",
        "    description=model_description,\n",
        "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
        "    serving_container_predict_route=predict_route,\n",
        "    serving_container_health_route=health_route,\n",
        "    serving_container_ports=serving_container_ports,\n",
        ")\n",
        "\n",
        "model.wait()\n",
        "\n",
        "print(model.display_name)\n",
        "print(model.resource_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e5bf859-5648-4f0e-ac16-91453f854cff",
      "metadata": {
        "id": "7e5bf859-5648-4f0e-ac16-91453f854cff"
      },
      "outputs": [],
      "source": [
        "### Create an Endpoint for Model with Custom Container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd88c67-f2ea-42fc-a7cb-9bf895772f8b",
      "metadata": {
        "id": "3fd88c67-f2ea-42fc-a7cb-9bf895772f8b",
        "outputId": "9fd670af-2db4-400a-db48-b4e9e24a71ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
            "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/425328907110/locations/us-central1/endpoints/2463548161008861184/operations/7923365631984926720\n",
            "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/425328907110/locations/us-central1/endpoints/2463548161008861184\n",
            "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
            "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/425328907110/locations/us-central1/endpoints/2463548161008861184')\n"
          ]
        }
      ],
      "source": [
        "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
        "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e2186ad-62cf-4949-a07c-cdfedce45da4",
      "metadata": {
        "tags": [],
        "id": "2e2186ad-62cf-4949-a07c-cdfedce45da4",
        "outputId": "77ef48e4-dd7b-4baa-bb7d-d72d57384305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/425328907110/locations/us-central1/endpoints/2463548161008861184\n",
            "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/425328907110/locations/us-central1/endpoints/2463548161008861184/operations/3832830532937318400\n",
            "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/425328907110/locations/us-central1/endpoints/2463548161008861184\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<google.cloud.aiplatform.models.Endpoint object at 0x7f1194277590> \n",
              "resource name: projects/425328907110/locations/us-central1/endpoints/2463548161008861184"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trffc_percentage = 100\n",
        "mach_type = \"n1-standard-4\"\n",
        "dpd_model_display_name = model_display_name\n",
        "mn_replica_count = 1\n",
        "mx_replica_count = 3\n",
        "sync = True\n",
        "\n",
        "model.deploy(\n",
        "    endpoint=endpoint,\n",
        "    dpd_model_display_name=deployed_model_display_name,\n",
        "    mach_type=machine_type,\n",
        "    trffc_percentage=traffic_percentage,\n",
        "    sync=sync,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "160a0964-c782-48cf-90b0-368f93a7d679",
      "metadata": {
        "id": "160a0964-c782-48cf-90b0-368f93a7d679",
        "outputId": "a7e93a2a-0f4e-47af-fa05-581f580c2a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint display name = finetuned-bert-classifier-endpoint resource id =projects/425328907110/locations/us-central1/endpoints/2463548161008861184 \n"
          ]
        }
      ],
      "source": [
        "endpoint_name = f\"{APP_NAME}-endpoint\"\n",
        "fltr = f'display_name=\"{endpoint_name}\"'\n",
        "\n",
        "for endpoint_info in aiplatform.Endpoint.list(filter=fltr):\n",
        "    print(\n",
        "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
        "    )\n",
        "\n",
        "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b20ee46a-1b1f-498f-8096-59b3de17b091",
      "metadata": {
        "id": "b20ee46a-1b1f-498f-8096-59b3de17b091",
        "outputId": "c67ab4e3-8356-4b8d-9795-017d39afafdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[id: \"2249662363080851456\"\n",
              "model: \"projects/425328907110/locations/us-central1/models/7271840052622131200\"\n",
              "display_name: \"finetuned-bert-classifier-v1\"\n",
              "create_time {\n",
              "  seconds: 1639090350\n",
              "  nanos: 175393000\n",
              "}\n",
              "dedicated_resources {\n",
              "  machine_spec {\n",
              "    machine_type: \"n1-standard-4\"\n",
              "  }\n",
              "  min_replica_count: 1\n",
              "  max_replica_count: 1\n",
              "}\n",
              "]"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "endpoint.list_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29737340-9f10-45f0-a858-a8cb3af6b18a",
      "metadata": {
        "id": "29737340-9f10-45f0-a858-a8cb3af6b18a"
      },
      "outputs": [],
      "source": [
        "tstt_instances = [\n",
        "    b\"Jaw dropping visual affects and action! One of the best I have seen to date.\",\n",
        "    b\"Take away the CGI and the A-list cast and you end up with film with less punch.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b0dc6ac-efe5-49f8-bae1-d64b1e62704e",
      "metadata": {
        "id": "8b0dc6ac-efe5-49f8-bae1-d64b1e62704e",
        "outputId": "118e7e6d-fb77-47d1-80ac-8e2cc68d6419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Input text: \n",
            "\tJaw dropping visual affects and action! One of the best I have seen to date.\n",
            "\n",
            "Formatted input: \n",
            "[\n",
            "    {\n",
            "        \"data\": {\n",
            "            \"b64\": \"SmF3IGRyb3BwaW5nIHZpc3VhbCBhZmZlY3RzIGFuZCBhY3Rpb24hIE9uZSBvZiB0aGUgYmVzdCBJIGhhdmUgc2VlbiB0byBkYXRlLg==\"\n",
            "        }\n",
            "    }\n",
            "]\n",
            "\n",
            "Prediction response: \n",
            "\tPrediction(predictions=['Joy'], deployed_model_id='2249662363080851456', explanations=None)\n",
            "====================================================================================================\n",
            "Input text: \n",
            "\tTake away the CGI and the A-list cast and you end up with film with less punch.\n",
            "\n",
            "Formatted input: \n",
            "[\n",
            "    {\n",
            "        \"data\": {\n",
            "            \"b64\": \"VGFrZSBhd2F5IHRoZSBDR0kgYW5kIHRoZSBBLWxpc3QgY2FzdCBhbmQgeW91IGVuZCB1cCB3aXRoIGZpbG0gd2l0aCBsZXNzIHB1bmNoLg==\"\n",
            "        }\n",
            "    }\n",
            "]\n",
            "\n",
            "Prediction response: \n",
            "\tPrediction(predictions=['Joy'], deployed_model_id='2249662363080851456', explanations=None)\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 100)\n",
        "for instance in test_instances:\n",
        "    print(f\"Input text: \\n\\t{instance.decode('utf-8')}\\n\")\n",
        "    b64_encoded = base64.b64encode(instance)\n",
        "    test_instance = [{\"data\": {\"b64\": f\"{str(b64_encoded.decode('utf-8'))}\"}}]\n",
        "    print(f\"Formatted input: \\n{json.dumps(tst_instance, indent=4)}\\n\")\n",
        "    prediction = endpoint.predict(instances=tst_instance)\n",
        "    print(f\"Prediction response: \\n\\t{prediction}\")\n",
        "    print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e30031-fdc8-43c5-995f-470d9c24d34d",
      "metadata": {
        "id": "90e30031-fdc8-43c5-995f-470d9c24d34d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "pytorch-gpu.1-9.m82",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}